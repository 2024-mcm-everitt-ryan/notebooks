{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T00:52:57.004731Z",
     "start_time": "2024-06-19T00:52:57.001710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "model_id = 'meta-llama/Meta-Llama-3-70B-Instruct'\n",
    "model_name = 'Meta-Llama-3-70B-Instruct'"
   ],
   "id": "cc08ead42cced330",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T00:53:43.554520Z",
     "start_time": "2024-06-19T00:53:43.552136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import huggingface_hub\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "def openai_chat(messages):\n",
    "    client = OpenAI(\n",
    "        base_url=f\"https://api-inference.huggingface.co/models/{model_id}/v1/\",\n",
    "        #base_url='https://twkby3tkl3wdjrta.us-east-1.aws.endpoints.huggingface.cloud/v1/',\n",
    "        api_key=huggingface_hub.get_token(),\n",
    "    )\n",
    "\n",
    "    return client.chat.completions.create(\n",
    "        model=model_id,\n",
    "        messages=messages,\n",
    "        stream=False,\n",
    "        max_tokens=1512\n",
    "    )"
   ],
   "id": "f425a1a02b015fd7",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T00:53:44.068020Z",
     "start_time": "2024-06-19T00:53:44.064640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "def api_key():\n",
    "    with open(f\"{os.environ['HOME']}/HuggingFace-API-DCU-AI.key\", 'r') as file:\n",
    "        return file.read().strip()\n",
    "\n",
    "\n",
    "def api_url():\n",
    "    #return f\"https://api-inference.huggingface.co/models/{model_id}\"\n",
    "    return 'https://twkby3tkl3wdjrta.us-east-1.aws.endpoints.huggingface.cloud'\n",
    "\n",
    "\n",
    "def api_headers():\n",
    "    return {\n",
    "        \"Authorization\": f\"Bearer {api_key()}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "\n",
    "def api_query(inputs):\n",
    "    # https://huggingface.co/blog/inference-pro#controlling-text-generation\n",
    "    # Looks like some params are for HF pro accounts\n",
    "    payload = {\n",
    "        \"inputs\": inputs,\n",
    "        \"parameters\": {\n",
    "            \"max_new_tokens\": 800,\n",
    "            #\"do_sample\": True,\n",
    "            \"temperature\": 0.7,\n",
    "            #\"top_p\": 0.25,\n",
    "            #\"top_k\": 40,\n",
    "            # \"repetition_penalty\": 1.1,\n",
    "            \"return_full_text\": False,\n",
    "            \"seed\": 2024\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return requests.post(api_url(), headers=api_headers(), json=payload).json()\n"
   ],
   "id": "d88492a19710c441",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T00:53:53.531725Z",
     "start_time": "2024-06-19T00:53:53.528974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import os\n",
    "\n",
    "client = InferenceClient(model=model_id, token=api_key())"
   ],
   "id": "1e919552b2379869",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T00:54:04.765187Z",
     "start_time": "2024-06-19T00:54:04.762773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chat(messages):\n",
    "    return client.chat_completion(\n",
    "        model=model_id,\n",
    "        messages=messages,\n",
    "        temperature=0.8,\n",
    "        stream=False,\n",
    "        max_tokens=800\n",
    "    ).choices[0].message.content"
   ],
   "id": "bbd5fda469a71300",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T00:54:06.689484Z",
     "start_time": "2024-06-19T00:54:06.687740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#import json\n",
    "#import tiktoken\n",
    "\n",
    "#encoding = tiktoken.encoding_for_model(\"gpt2\")\n",
    "#len(encoding.encode(json.dumps(c)))"
   ],
   "id": "a1ad390067040989",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T02:15:53.070727Z",
     "start_time": "2024-06-22T02:15:53.053035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = 'augmented-taxonomies.parquet'\n",
    "\n",
    "taxonomies = pd.read_parquet(path)\n",
    "taxonomies = taxonomies[taxonomies['source'] != 'synthetic']\n",
    "taxonomies['term'] = taxonomies['term'].str.lower()\n",
    "# Remove duplicate rows in the 'term'  column\n",
    "taxonomies = taxonomies.drop_duplicates(subset='term')\n",
    "taxonomies['reason'] = taxonomies['reason'].str.replace('^synthetic:gpt-4o:', '', regex=True)\n",
    "taxonomies = taxonomies[['source', 'category', 'term', 'reason']]\n",
    "taxonomies"
   ],
   "id": "73e55065002fb72c",
   "execution_count": 60,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T02:16:05.740704Z",
     "start_time": "2024-06-22T02:16:05.736621Z"
    }
   },
   "cell_type": "code",
   "source": "taxonomies['source'].value_counts()",
   "id": "dbdd57f3a90e2271",
   "execution_count": 61,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T02:16:10.148949Z",
     "start_time": "2024-06-22T02:16:10.144565Z"
    }
   },
   "cell_type": "code",
   "source": "taxonomies['category'].value_counts()",
   "id": "4981e6212747a0",
   "execution_count": 62,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Generate Synthetic samples",
   "id": "901710a3613e417f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T02:16:26.792473Z",
     "start_time": "2024-06-22T02:16:26.788838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fetch a job title from job-phrase-list.csv\n",
    "# Original source of list: https://github.com/microsoft/LUIS-Samples/blob/master/documentation-samples/tutorials/job-phrase-list.csv\n",
    "\n",
    "import random\n",
    "\n",
    "def random_job_title():\n",
    "    with open(\"job-phrase-list.csv\", \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    return random.choice(lines).replace(',\\n', '')\n",
    "\n",
    "\n",
    "random_job_title()"
   ],
   "id": "f6ca3016e760eb74",
   "execution_count": 63,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d = []\n",
    "d.append('test')\n",
    "d.append('test2')\n"
   ],
   "id": "d4a68b4d2d02e8da",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T16:17:51.335625Z",
     "start_time": "2024-06-20T16:17:51.328720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def generate_text(position, category_terms, dry_run=False):\n",
    "    m = []\n",
    "    \n",
    "    # Define categories\n",
    "    for category in categories:\n",
    "        with open(f\"definitions/{category}.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "            definition = f.read()\n",
    "        m.append({\"role\": \"user\", \"content\": f\"Define job description bias category: {category}\"})\n",
    "        m.append({\"role\": \"assistant\", \"content\": definition})\n",
    "    \n",
    "    # Provide some samples\n",
    "    for category, samples in category_terms.items():\n",
    "        #with open(f\"definitions/{category}.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "        #    definition = f.read()\n",
    "        #m.append({\"role\": \"user\", \"content\": f\"Define job description bias category: {category}\"})\n",
    "        #m.append({\"role\": \"assistant\", \"content\": definition})\n",
    "        for row in samples.itertuples():\n",
    "            #print(f\"{category}: {row.term}: {row.reason}\")\n",
    "            m.append({\"role\": \"user\", \"content\": f\"Why is the term `{row.term}` considered implicit {category} bias?\"})\n",
    "            m.append({\"role\": \"assistant\", \"content\": row.reason})\n",
    "    \n",
    "    # Provide the task\n",
    "    task = f\"The study of reducing the biases and terms provided is important, but an example is important to demonstrate what implicit bias can manifest in real job descriptions. Your task is to generate a complete job description that demonstrates the subtleties of bias within the specified framework, while maintaining inclusivity and reducing bias in all other respects. Adhere to the following requirements:\"\n",
    "    \n",
    "    task += f\"\\n- The role is \\\"{position}\\\".\"\n",
    "    task += f\"\\n- Max 400 words.\"\n",
    "    task += f\"\\n- Adhere to the bias category definitions.\"\n",
    "    for category, samples in category_terms.items():\n",
    "        task += f\"\\n- Uses the following terms to introduce subtle/implicit {category} bias/non-inclusive language:\"\n",
    "        for row in samples.itertuples():\n",
    "            task += f\"\\n  * {row.term}\"\n",
    "             \n",
    "    task += f\"\\n- It is crucial that you do not introduce any additional forms of bias from the other categories defined.\"\n",
    "    task += f\"\\n- Ensure that all other aspects of the job description are inclusive and unbiased.\"\n",
    "    task += f\"\\n- Encapsulate the final job description within <j>...</j> tags.\"\n",
    "    for category, samples in category_terms.items():\n",
    "        task += f\"\\n- Encapsulate a sentence within <{category}>...</{category} tags as to how bias was introduced into the job description\"\n",
    "    m.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": task\n",
    "    })\n",
    "\n",
    "    if not dry_run:\n",
    "        start_time = time.time()\n",
    "        output = openai_chat(m)\n",
    "        inference_time = time.time() - start_time\n",
    "\n",
    "        prompt_tokens = output.usage.prompt_tokens\n",
    "        completion_tokens = output.usage.completion_tokens\n",
    "        total_tokens = output.usage.total_tokens\n",
    "        content = output.choices[0].message.content\n",
    "\n",
    "        #return json.dumps(m), chat(m)\n",
    "        return json.dumps(m), content, inference_time, prompt_tokens, completion_tokens, total_tokens\n",
    "    else:\n",
    "        return json.dumps(m), None, None, None, None, None\n"
   ],
   "id": "57bb5b5d8b134a67",
   "execution_count": 50,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Using the provided categories and terms, generate a 400-word job description that illustrates the presence of subtle bias language typically found in job postings. Ensure that the job description strictly adheres to the terms and categories provided, and avoid introducing any biases not explicitly specified. Encapsulate the job description within <j>...</j> tags. After the job description, include the category information within XML tags named according to the last category you used (e.g., <{last_cat}>...</{last_cat}>). Your output should demonstrate how subtle biases can be embedded in job descriptions without adding any new forms of bias.",
   "id": "d93b2209748235a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Generate a 400-word job description using only the biases and terms provided. It is crucial that you do not introduce any additional forms of bias. Ensure that all other aspects of the job description are inclusive and unbiased. Encapsulate the final job description within <j>...</j> tags. After the job description, include the category information within XML tags named according to the last category you used (e.g., <{last_cat}>...</{last_cat}>). Your task is to demonstrate the subtleties of bias within the specified framework, while maintaining inclusivity and reducing bias in all other respects.",
   "id": "7fb2c22379d9f028"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T01:24:24.398195Z",
     "start_time": "2024-06-19T01:24:24.394558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "test_data_size = 500\n",
    "min_test_split_size = 0.05 \n",
    "\n",
    "categories = ['age', 'disability', 'feminine', 'masculine', 'racial', 'sexuality', 'general']\n",
    "splits = len(categories) + 1\n",
    "size = 3000 #int(math.ceil((test_data_size / min_test_split_size) / splits)) \n",
    "max_additional_categories = 4  # Maximum number of additional categories per sample\n",
    "\n",
    "label_categories = ['label_' + category for category in categories]\n",
    "analysis_categories = ['analysis_' + category for category in categories]"
   ],
   "id": "c5dad10d1d8d65bd",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T15:50:48.797143Z",
     "start_time": "2024-06-20T15:50:48.790841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "output_dir = '/home/teveritt/Datasets/2024-mcm-everitt-ryan/datasets/synthetic-job-postings/pass3'\n",
    "output_file = f'{output_dir}/synthetic-biased-job-descriptions-sync.jsonl'\n",
    "\n",
    "if os.path.exists(output_file):\n",
    "    synthetic_df = pd.read_json(output_file, lines=True)\n",
    "else:\n",
    "    synthetic_df = pd.DataFrame(\n",
    "        columns=[\"document_id\", \"position\"] + label_categories + analysis_categories + [\"inference_time\", \"prompt_tokens\",\n",
    "                                                                  \"completion_tokens\",\n",
    "                                                                  \"total_tokens\", \"text\", \"input\", \"output\"])\n",
    "\n",
    "synthetic_df"
   ],
   "id": "26a902303fa23b76",
   "execution_count": 44,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T16:18:18.599303Z",
     "start_time": "2024-06-20T16:17:56.030908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from itertools import cycle\n",
    "import random\n",
    "import math\n",
    "import hashlib\n",
    "\n",
    "categories_cycle = cycle(categories)\n",
    "\n",
    "# Dictionary to keep track of the count of samples in each category\n",
    "category_count = {category: 0 for category in categories}\n",
    "\n",
    "\n",
    "def create_hash(input_string):\n",
    "    return hashlib.sha256(input_string.encode()).hexdigest()[:10]\n",
    "\n",
    "\n",
    "def extract_job_posting(text):\n",
    "    content = re.findall(r'<j>(.*?)</j>', text, re.DOTALL)\n",
    "    ret = [c.strip() for c in content]\n",
    "    return ret[0] if len(ret) > 0 else text\n",
    "\n",
    "def find_first_between_tags(file_content, tag):\n",
    "    start_tag = f\"<{tag}>\"\n",
    "    end_tag = f\"</{tag}>\"\n",
    "\n",
    "    start_index = file_content.find(start_tag)\n",
    "    end_index = file_content.find(end_tag)\n",
    "\n",
    "    if start_index != -1 and end_index != -1:  # tags were found\n",
    "        start_index += len(start_tag)  # adjust to index after the start tag\n",
    "        result = file_content[start_index:end_index].strip()  # extract content between tags\n",
    "        return result\n",
    "\n",
    "    return None  # tags were not found or improperly formatted\n",
    "\n",
    "dry_run = False\n",
    "\n",
    "# Iterate through the categories in a round-robin fashion \n",
    "iter_size = size + len(categories)\n",
    "for i in range(iter_size):\n",
    "    category = next(categories_cycle)\n",
    "    if not dry_run:\n",
    "        print(f'{i}/{iter_size} Generating synthetic for category {category}')\n",
    "\n",
    "    while category_count[category] >= size:\n",
    "        # If the current category has already reached the size, \n",
    "        # we take the next category on the list\n",
    "        category = next(categories_cycle)\n",
    "\n",
    "    additional_categories = random.sample(categories, k=random.randint(0, max_additional_categories))\n",
    "    additional_categories = set(additional_categories)\n",
    "    additional_categories.add(category)\n",
    "\n",
    "    # Don't include both to reduce confusing the model\n",
    "    if 'masculine' in additional_categories and 'feminine' in additional_categories:\n",
    "        additional_categories.remove('feminine')\n",
    "        additional_categories.remove('masculine')\n",
    "        additional_categories.add(random.choice(['masculine', 'feminine']))\n",
    "\n",
    "    category_sample = int(math.ceil(max_additional_categories / len(additional_categories)))\n",
    "    category_sample = random.randint(1, category_sample)\n",
    "    category_terms = {}\n",
    "    for cat in additional_categories:\n",
    "        category_terms[cat] = taxonomies[taxonomies['category'] == cat].sample(category_sample)\n",
    "\n",
    "    position = random_job_title()\n",
    "\n",
    "    # Generate text sample with category information\n",
    "    #prompt, output = generate_text(category_terms)\n",
    "    prompt, output, inference_time, prompt_tokens, completion_tokens, total_tokens = generate_text(position,\n",
    "                                                                                                   category_terms,\n",
    "                                                                                                   dry_run)\n",
    "    text = find_first_between_tags(output,'j') if not dry_run else None\n",
    "    analysis_age = find_first_between_tags(output, 'age')\n",
    "    analysis_disability = find_first_between_tags(output, 'disability')\n",
    "    analysis_feminine = find_first_between_tags(output, 'feminine')\n",
    "    analysis_masculine = find_first_between_tags(output, 'masculine')\n",
    "    analysis_racial = find_first_between_tags(output, 'racial')\n",
    "    analysis_sexuality = find_first_between_tags(output, 'sexuality')\n",
    "    analysis_general = find_first_between_tags(output, 'general')\n",
    "    \n",
    "    \n",
    "    category_count[category] += 1\n",
    "\n",
    "    timestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "    id = create_hash(output) if not dry_run else i\n",
    "    id = f\"{timestamp}:{id}\"\n",
    "    id_m = model_id.replace('/', ':')\n",
    "    data = {\n",
    "        \"document_id\": f'Synthetic:{id_m}:{id}',\n",
    "        \"position\": position\n",
    "    }\n",
    "    for cat in categories:\n",
    "        data[f'label_{cat}'] = False\n",
    "\n",
    "    data['inference_time'] = inference_time\n",
    "    data['prompt_tokens'] = prompt_tokens\n",
    "    data['completion_tokens'] = completion_tokens\n",
    "    data['total_tokens'] = total_tokens\n",
    "    data['text'] = text\n",
    "    data['analysis_age'] = analysis_age\n",
    "    data['analysis_disability'] = analysis_disability\n",
    "    data['analysis_feminine'] = analysis_feminine\n",
    "    data['analysis_masculine'] = analysis_masculine\n",
    "    data['analysis_racial'] = analysis_racial\n",
    "    data['analysis_sexuality'] = analysis_sexuality\n",
    "    data['analysis_general'] = analysis_general\n",
    "    data['input'] = prompt\n",
    "    data['output'] = output\n",
    "    \n",
    "    for cat in additional_categories:\n",
    "        data[f'label_{cat}'] = True\n",
    "\n",
    "    if not dry_run:\n",
    "        with open(output_file, 'a') as file:\n",
    "            if not os.stat(output_file).st_size == 0:\n",
    "                file.write('\\n')\n",
    "            file.write(json.dumps(data))\n",
    "\n",
    "    synthetic_df = pd.concat([synthetic_df, pd.DataFrame(data, index=[0])], ignore_index=True)\n",
    "    break\n",
    "\n",
    "synthetic_df"
   ],
   "id": "ecbc61aad3248d4c",
   "execution_count": 51,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T16:18:18.604640Z",
     "start_time": "2024-06-20T16:18:18.600776Z"
    }
   },
   "cell_type": "code",
   "source": "print(synthetic_df.tail(1)['text'].values[0])",
   "id": "872d5832dd3998ca",
   "execution_count": 52,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T19:27:52.819951Z",
     "start_time": "2024-06-20T19:27:52.461576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "i = \"\"\"\n",
    "This GPT is designed to detect implicit bias and non-inclusive language in job descriptions. It will analyse text for specific categories of bias and return two concise sentences (using British spelling and grammar) explaining the detected bias for each relevant category, without providing additional information. The possible categories of bias it can detect are: age, disability, feminine, general, masculine, racial, and sexuality.  Only list the ones detected, ignore the rest.  If none are detected, say \"None detected\".\n",
    "\n",
    "Role and Goal: The GPT should identify implicit biases and non-inclusive language in job descriptions, providing a clear and succinct explanation of the bias detected for each relevant category. It should focus only on the labels detected and avoid extraneous information.\n",
    "\n",
    "Constraints: The GPT should only output two sentences per detected bias and should not include additional commentary or information beyond the explanation of the bias. It should strictly only output the provided categories and adhere to the definitions provided for each category of bias.\n",
    "\n",
    "Guidelines: The GPT should follow the specific examples and language cues given in the definitions for each category of bias. It should use precise and professional language in its explanations.\n",
    "\n",
    "Clarification: The GPT should not ask for clarification but should make a best effort to analyze the text and provide accurate detections based on the provided definitions.  If no bias detected, say \"None detected\".\n",
    "\n",
    "Personalization: The GPT should maintain a neutral, informative tone and focus on delivering clear, concise explanations of the detected biases.\n",
    "\n",
    "Output format: For each category detected, wrap the sentences with the category tag.  For example, if racial, age, disability are detected then the output should be: <racial>The concise explanation here.</racial><age>The concise explanation here.</age><disability>The concise explanation here.</disability> \n",
    "\n",
    "Age bias definition: Occurs when language or requirements subtly favour certain age groups over others. Common categories include insensitive terms (e.g., \"geezer\"), language implying energy or modernity (e.g., \"young and dynamic\", \"recent graduate\") that favour younger candidates, as well as language implying experience and wisdom (e.g., \"seasoned professional\", \"mature\") that favour older candidates.\n",
    "\n",
    "Disability bias definition: Involves the use of terms or requirements that inadvertently exclude or disadvantage individuals based on disabilities. This can include physical, mental, sensory, or cognitive impairments. Common categories include ableist terms that imply the requirement of a physical trait (e.g., \"type 50 words per minute\") instead of focusing on the job function (e.g., \"enter data at 50 words per minute\"), unnecessary physical requirements (e.g., \"must be able to lift 50 pounds\" for a desk job), and the absence of language regarding reasonable accommodations to ensure that candidates with disabilities are assessed based on their suitability for the role.\n",
    "\n",
    "Feminine bias definition: Refers to language that subtly favours or resonates more with female candidates.  Common categories include gender-coded words (e.g., \"nurturing,\" \"supportive\"), domestic or caregiving metaphors, an emphasis on collaborative over individualistic skills, and gendered job titles (e.g., \"hostess\") and pronouns (e.g., \"she/her\").\n",
    "\n",
    "General bias definition: Occurs when language or requirements use derogatory (e.g. \"feminazi\", \"retarded\") or outdated terms (e.g. \"the disabled\"), or subtly favour or disadvantage candidates based on various characteristics. Common categories include socio-economic status (e.g., \"blue-collar\"), educational background (e.g., \"Degree from a top school\"), mental health (e.g., \"OCD\"), gender and family roles (e.g., \"clean-shaven\", \"maternity leave\"), veteran status, criminal history, and political or ideological beliefs.\n",
    "\n",
    "Masculine bias definition: Refers to language that subtly favours or resonates more with male candidates. Common categories include gender-coded words (e.g., \"dominant\", \"competitive\"), sports or military metaphors, an emphasis on individualistic over collaborative skills, and gendered job titles (e.g., \"salesman\") and pronouns (e.g., \"he/him\").\n",
    "\n",
    "Racial bias definition: Occurs when language or requirements subtly favour certain racial groups or exclude others. Common categories include racially insensitive terms (e.g., \"master/slave\", \"redneck\"), exclusionary phrases (e.g., \"brown-bag session\", \"white/black list\"), and assumptions about linguistic proficiency or background (e.g., \"native English speaker\").\n",
    "\n",
    "Sexuality bias definition: Occurs when language or requirements subtly favour certain sexual orientations, gender identities, or expressions over others, creating non-inclusive language that can exclude LGBTQ+ individuals. Common categories include terms that enforce heteronormativity (e.g., \"the men and women\", \"opposite sex\"), outdated or offensive terminology (e.g., \"homosexual\", \"tranny\"), lack of recognition of diverse family structures (e.g., \"wife and husband\" instead of \"partner\" or \"spouse\"), assumptions about gender identity (e.g., \"born a man\", \"sex change\"), and non-inclusive pronouns (e.g., \"he/she\" instead of \"they\" or \"you\").\n",
    "\"\"\"\n",
    "\n",
    "m = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": i\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": synthetic_df.head(1)['text'].values[0]\n",
    "    }\n",
    "]\n",
    "\n",
    "openai_chat(m)"
   ],
   "id": "6d75942d26addb9",
   "execution_count": 58,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T12:13:22.341383Z",
     "start_time": "2024-06-19T12:13:21.700232Z"
    }
   },
   "cell_type": "code",
   "source": "synthetic_df.to_parquet(f'{output_dir}/synthetic-biased-job-descriptions.parquet', compression='gzip')",
   "id": "958d265f773e7c20",
   "execution_count": 35,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T12:13:22.348983Z",
     "start_time": "2024-06-19T12:13:22.342377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for cat in categories:\n",
    "    print(synthetic_df[f'label_{cat}'].value_counts())"
   ],
   "id": "9c18d335bd73363a",
   "execution_count": 36,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T09:49:25.751174Z",
     "start_time": "2024-06-20T09:49:25.745307Z"
    }
   },
   "cell_type": "code",
   "source": "synthetic_df[label_categories].tail(1)",
   "id": "6d176f9bdd418df1",
   "execution_count": 43,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T12:13:22.363225Z",
     "start_time": "2024-06-19T12:13:22.360817Z"
    }
   },
   "cell_type": "code",
   "source": "print(synthetic_df['text'].iloc[-1])",
   "id": "567fa9b01e93af0",
   "execution_count": 38,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:56:13.566291Z",
     "start_time": "2024-06-18T09:56:13.562256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Longest phrase\n",
    "longest_text = synthetic_df['text'].apply(lambda x: (len(x), x)).max()[1]\n",
    "longest_text"
   ],
   "id": "b94db31a27d932d4",
   "execution_count": 207,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:56:54.853915Z",
     "start_time": "2024-06-18T09:56:53.275086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "def print_max_tokens(model_id):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, add_prefix_space=True)\n",
    "    max_tokens = len(tokenizer.encode(longest_text))\n",
    "    print(f\"Max '{model_id}' tokens: {max_tokens}\")\n",
    "\n",
    "def print_encode_decoded(model_id, longest_text):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, add_prefix_space=True)\n",
    "    encoded_tokens = tokenizer.encode(longest_text)\n",
    "    print(f\"Tokens: {encoded_tokens}\")\n",
    "    print(f\"Decoded tokens: {tokenizer.decode(encoded_tokens)}\")\n",
    "    \n",
    "def print_tokens(model_id, longest_text):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, add_prefix_space=True)\n",
    "    tokens = tokenizer.tokenize(longest_text)\n",
    "    print(f\"Tokens: {tokens}\")\n",
    "    "
   ],
   "id": "a832d085734ac7e5",
   "execution_count": 208,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:57:04.635166Z",
     "start_time": "2024-06-18T09:57:03.365349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_char = len(longest_text)\n",
    "max_words = len(longest_text.split())\n",
    "\n",
    "print(f'Max characters: {max_char}')\n",
    "print(f'Max words: {max_words}')\n",
    "for model_id in ['roberta-base', 'bert-base-uncased', 'microsoft/deberta-v3-small']:\n",
    "    print_max_tokens(model_id)\n"
   ],
   "id": "a54d9b5d5a70b109",
   "execution_count": 209,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:58:12.106876Z",
     "start_time": "2024-06-18T09:58:12.104138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Source: https://colab.research.google.com/drive/1pddMaJJIHR0O8MND42hfzYRxOPMV82KA?usp=sharing#scrollTo=RkVuiK_loty4\n",
    "\n",
    "def categorical_entropy(df, labels):\n",
    "    # entropy for labels across the dataset\n",
    "    # p(l) = count(l) / sum(count(l) for l in labels))\n",
    "    # H = sum(p(l) * -log2 p(l) for l in labels)\n",
    "    cat_sums = df[labels].sum()\n",
    "    cat_probs = np.array([cs / cat_sums.sum() for cs in cat_sums])\n",
    "    return np.sum(cat_probs * -np.log2(cat_probs))"
   ],
   "id": "af9b3d55eb0f8a3",
   "execution_count": 210,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:58:40.762772Z",
     "start_time": "2024-06-18T09:58:40.758941Z"
    }
   },
   "cell_type": "code",
   "source": "label_categories",
   "id": "fce609736e74416e",
   "execution_count": 211,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:58:47.232507Z",
     "start_time": "2024-06-18T09:58:47.227455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# entropy for original dataset\n",
    "categorical_entropy(synthetic_df, label_categories)"
   ],
   "id": "37052df14f67c555",
   "execution_count": 212,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T10:11:57.744318Z",
     "start_time": "2024-06-18T10:11:57.711808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dedup_df = pd.read_parquet('/home/teveritt/Datasets/2024-mcm-everitt-ryan/datasets/synthetic-jobs/synthetic-biased-job-descriptions-deduped.parquet')\n",
    "dedup_df"
   ],
   "id": "17f7f2b7da0d60ce",
   "execution_count": 214,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T10:12:11.524940Z",
     "start_time": "2024-06-18T10:12:11.521434Z"
    }
   },
   "cell_type": "code",
   "source": "categorical_entropy(dedup_df, label_categories)\n",
   "id": "b2520405533b8405",
   "execution_count": 215,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T10:13:06.655989Z",
     "start_time": "2024-06-18T10:13:06.650101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for cat in categories:\n",
    "    print(dedup_df[f'label_{cat}'].value_counts())"
   ],
   "id": "e2dba5966625a70b",
   "execution_count": 216,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T10:17:08.732931Z",
     "start_time": "2024-06-18T10:17:08.636436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {}\n",
    "\n",
    "for cat in categories:\n",
    "    counts = dedup_df[f'label_{cat}'].value_counts()\n",
    "    data[cat] = counts\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "plt.figure(figsize=(20, 16))  # set plot figure size here\n",
    "df.plot(kind='bar', stacked=True)\n",
    "plt.title('Distribution of the 7 Categories')\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()"
   ],
   "id": "3219b072a521ac29",
   "execution_count": 223,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T10:19:30.324343Z",
     "start_time": "2024-06-18T10:19:30.241534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "data = {} \n",
    "\n",
    "for cat in categories:\n",
    "    counts = dedup_df[f'label_{cat}'].value_counts()\n",
    "    data[cat] = counts\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "df.plot(kind='barh', stacked=True)\n",
    "\n",
    "plt.title('Distribution of the 7 Categories')\n",
    "plt.ylabel('Categories')\n",
    "plt.xlabel('Counts')\n",
    "plt.show()\n"
   ],
   "id": "e23bd4aab821fd86",
   "execution_count": 226,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "d7289d2642261b39",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
