{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T18:00:09.268103Z",
     "start_time": "2024-06-30T18:00:09.264668Z"
    }
   },
   "cell_type": "code",
   "source": "category = 'feminine'",
   "id": "585e87ba2b57864a",
   "execution_count": 43,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T18:41:14.607688Z",
     "start_time": "2024-06-30T18:41:14.603992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import huggingface_hub\n",
    "from openai import OpenAI\n",
    "\n",
    "temperature = 0.8\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    return content.rstrip('\\n')\n",
    "\n",
    "use_gpt_model = False\n",
    "\n",
    "if use_gpt_model:\n",
    "    model = 'gpt-4o'\n",
    "    model_shortname = 'gpt4o'\n",
    "    base_url = None\n",
    "    api_key=read_file(\"/home/teveritt/OpenAI-API-DCU-AI.key\")\n",
    "else:\n",
    "    model = 'meta-llama/Meta-Llama-3-70B-Instruct'\n",
    "    model_shortname = 'llama3b70'\n",
    "    base_url = f\"https://api-inference.huggingface.co/models/{model}/v1/\"\n",
    "    #base_url='https://ylzx7jabydlt5hql.us-east-1.aws.endpoints.huggingface.cloud/v1/'\n",
    "    api_key=huggingface_hub.get_token()\n",
    "\n",
    "def openai_chat(messages):\n",
    "    client = OpenAI(base_url=base_url, api_key=api_key)\n",
    "\n",
    "    return client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=messages,\n",
    "        stream=False,\n",
    "        max_tokens=1525\n",
    "    )"
   ],
   "id": "f425a1a02b015fd7",
   "execution_count": 74,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T18:41:15.185727Z",
     "start_time": "2024-06-30T18:41:15.182280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fetch a job title from job-phrase-list.csv\n",
    "# Original source of list: https://github.com/microsoft/LUIS-Samples/blob/master/documentation-samples/tutorials/job-phrase-list.csv\n",
    "# https://www.kaggle.com/datasets/estasney/job-titles?select=titles.csv\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def get_job_titles():\n",
    "    titles = set()\n",
    "    with open(\"microsoft-LUIS-job-phrase-list.csv\", \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            titles.add(line.replace(',\\n', '').replace('\\n', ''))\n",
    "\n",
    "    #kaggle_titles = pd.read_csv('kaggle-titles.csv')\n",
    "    #for col in kaggle_titles.columns:\n",
    "    #    if col.startswith('Title_'):\n",
    "    #        titles.update(kaggle_titles[col].dropna().unique())\n",
    "\n",
    "    return list(titles)\n",
    "\n",
    "\n",
    "positions = get_job_titles()\n",
    "\n",
    "\n",
    "def random_job_title():\n",
    "    return random.choice(positions)\n",
    "\n",
    "\n",
    "print(f'Positions: {len(positions)}')"
   ],
   "id": "f6ca3016e760eb74",
   "execution_count": 75,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T18:41:15.747310Z",
     "start_time": "2024-06-30T18:41:15.744980Z"
    }
   },
   "cell_type": "code",
   "source": "random_job_title()",
   "id": "dffdde008fc9d43c",
   "execution_count": 76,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T18:41:16.431526Z",
     "start_time": "2024-06-30T18:41:16.424637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_definition(category):\n",
    "    with open(f\"definitions/{category}.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "        return f.read().strip().replace('\\n','')\n",
    "\n",
    "def load_polarity_definition(category, polarity):\n",
    "    with open(f\"polarity-definitions/{category}-{polarity}.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "        return f.read().strip().replace('\\n','')\n",
    "\n",
    "\n",
    "def random_phrases(category, polarity, num_lines=None):\n",
    "    with open(f\"polarity-phrases/{category}-{polarity}.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "        all_lines = [line.rstrip('\\n') for line in f.readlines()]  # remove \\n\n",
    "        all_lines = [line if line.endswith('.') else line + '.' for line in all_lines]  # add . at the end\n",
    "        if num_lines is not None:\n",
    "            return random.sample(all_lines, num_lines)\n",
    "        else:\n",
    "            return all_lines"
   ],
   "id": "4fbb04f8a37d6cc9",
   "execution_count": 77,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T18:41:16.871178Z",
     "start_time": "2024-06-30T18:41:16.868037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system = f\"\"\"\n",
    "This GPT generates 200 word synthetic job postings across seven categories: age, disability, feminine, masculine, racial, sexuality, and general. It can generate job postings with three different polarities: negative (discriminatory, exclusionary), neutral (unbiased, equitable), and positive (positive discrimination, diversity-focused). The job post builder adheres to the following definitions:\n",
    "\n",
    "- Age bias: {load_definition(category='age')}\n",
    "- Disability bias: {load_definition(category='disability')}\n",
    "- Feminine bias: {load_definition(category='feminine')}\n",
    "- General bias: {load_definition(category='general')}\n",
    "- Masculine bias: {load_definition(category='masculine')}\n",
    "- Racial bias: {load_definition(category='racial')}\n",
    "- Sexuality bias: {load_definition(category='sexuality')}\n",
    "\n",
    "The generator will provide company background, job type, job description, and responsibilities, qualifications and experience needed, perks and benefits. \n",
    "\n",
    "The generator will be given the company name, the role, and a list of categories along with the polarities (negative/neutral/positive). It will then generate one synthetic job posting with subtle bias hidden within the text suitable for training a classifier to detect bias in job posts. The subtle bias should not be similar to each other and obviously bias. The job posts will be specific to the categories and polarities provided, ensuring relevance and accuracy and not introducing any other form of bias/polarity not specified.\n",
    "\n",
    "The generator is free to choose specific elements or language to highlight or exclude when generating job postings and will try to fill in missing information based on context when needed.\n",
    "\"\"\""
   ],
   "id": "cf2693a2b21461e8",
   "execution_count": 78,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T18:41:17.617004Z",
     "start_time": "2024-06-30T18:41:17.558607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from faker import Faker\n",
    "\n",
    "categories = ['age', 'disability', 'feminine', 'masculine', 'racial', 'sexuality', 'general']\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "\n",
    "def get_inputs(position, inject_bias_types):\n",
    "    user_input = f\"\"\"Company: {fake.company()}\n",
    "Role: {position}\n",
    "Bias/Polarities:\"\"\"\n",
    "\n",
    "    for idx, type in enumerate(inject_bias_types):\n",
    "        category = type.split('/')[-2]\n",
    "        polarity = type.split('/')[-1]\n",
    "        definition = load_polarity_definition(category,polarity)\n",
    "        user_input += f\"\\n  {idx + 1}. {definition} Examples are:\"\n",
    "        for phrase in random_phrases(category, polarity, 5):\n",
    "            phrase = phrase.replace('\\n', '')\n",
    "            user_input += f\"\\n    - {phrase}\"\n",
    "\n",
    "    return user_input\n",
    "\n",
    "\n",
    "def get_output_format(inject_bias_types):\n",
    "    output_format = \"\"\"Review the job posting to make sure it has not introduced any other form of bias not specified and the rationale matches the bias/polarities specified. Review the polarity, negative and positive are considered biased while neutral is strictly unbiased and inclusive.  Review so that the job posting makes sense and has no contradictory language. Review the benefits/offer and if there is a lack of transparency (e.g. Competitive pay/salary), then adjust it to add more transparency (e.g \"We are committed to fair and equitable pay practices. The salary for this position ranges from <GPT fills this in> to <GPT fills this in>, based on your experience and skills\").  Pick one of global currency reserves when mentioning salary or revenue. Once reviewed and corrected, output with the following format (tag names are lowercase):\n",
    "  1. Wrap the job posting within the <j>...</j> tag.\"\"\"\n",
    "    for idx, type in enumerate(inject_bias_types):\n",
    "        category = type.split('/')[-2]\n",
    "        output_format += f\"\\n  {idx + 2}. Summarise, using third-person, the {category} rationale within one <{category}>...</{category}> tag.\"\n",
    "\n",
    "    return output_format\n",
    "\n",
    "\n",
    "def generate_text(position, inject_bias_types):\n",
    "    m = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system\n",
    "        }, {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": get_inputs(position, inject_bias_types)\n",
    "        }, {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"I have the job posting ready, how should I respond?\"\n",
    "        }, {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": get_output_format(inject_bias_types),\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    output = openai_chat(m)\n",
    "    inference_time = time.time() - start_time\n",
    "\n",
    "    prompt_tokens = output.usage.prompt_tokens\n",
    "    completion_tokens = output.usage.completion_tokens\n",
    "    total_tokens = output.usage.total_tokens\n",
    "    content = output.choices[0].message.content\n",
    "\n",
    "    #return json.dumps(m), chat(m)\n",
    "    return json.dumps(m), content, output.model, inference_time, prompt_tokens, completion_tokens, total_tokens"
   ],
   "id": "a45a28bfef073d72",
   "execution_count": 79,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T18:41:18.302146Z",
     "start_time": "2024-06-30T18:41:18.298331Z"
    }
   },
   "cell_type": "code",
   "source": "print(get_inputs(random_job_title(), [f'{category}/negative', f'{category}/neutral', f'{category}/positive']))",
   "id": "a94c87dda49d3705",
   "execution_count": 80,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T18:41:18.829086Z",
     "start_time": "2024-06-30T18:41:18.826709Z"
    }
   },
   "cell_type": "code",
   "source": "print(get_output_format([f'{category}/negative']))",
   "id": "e48803966f8ac21b",
   "execution_count": 81,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T18:41:20.096605Z",
     "start_time": "2024-06-30T18:41:20.090834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import hashlib\n",
    "\n",
    "\n",
    "def create_hash(input_string):\n",
    "    return hashlib.sha256(input_string.encode()).hexdigest()[:10]\n",
    "\n",
    "\n",
    "def lowercase_tags(text):\n",
    "    tags = re.findall(r'<\\/?\\w+', text)\n",
    "    for tag in tags:\n",
    "        text = text.replace(tag, tag.lower())\n",
    "    return text\n",
    "\n",
    "\n",
    "def extract_job_posting(text):\n",
    "    text = lowercase_tags(text)\n",
    "    content = re.findall(r'<j>(.*?)</j>', text, re.DOTALL)\n",
    "    ret = [c.strip() for c in content]\n",
    "    return ret[0] if len(ret) > 0 else text\n",
    "\n",
    "def fix_closing_tag(file_content, tag):\n",
    "    if f'<{tag}>' in file_content and f'</{tag}>' not in file_content:\n",
    "        return file_content + f'</{tag}>'\n",
    "    else:\n",
    "        return file_content\n",
    "\n",
    "def find_first_between_tags(file_content, tag):\n",
    "    file_content = fix_closing_tag(file_content, tag)\n",
    "    start_tag = f\"<{tag}>\"\n",
    "    end_tag = f\"</{tag}>\"\n",
    "\n",
    "    start_index = file_content.find(start_tag)\n",
    "    end_index = file_content.find(end_tag)\n",
    "\n",
    "    if start_index != -1 and end_index != -1:  # tags were found\n",
    "        start_index += len(start_tag)  # adjust to index after the start tag\n",
    "        result = file_content[start_index:end_index].strip()\n",
    "        result = result.replace('*', '')  # extract content between tags\n",
    "        return result\n",
    "\n",
    "    return None  # tags were not found or improperly formatted"
   ],
   "id": "68721f6541d0b03e",
   "execution_count": 82,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T18:41:20.990010Z",
     "start_time": "2024-06-30T18:41:20.982010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "output_dir = f'/home/teveritt/Datasets/2024-mcm-everitt-ryan/datasets/synthetic-job-postings/polarity-synthetic/{category}'\n",
    "jsonl_file = f'{output_dir}/polarity-synthetic-{model_shortname}.jsonl'\n",
    "parquet_file = f'{output_dir}/polarity-synthetic-{model_shortname}.parquet'\n",
    "\n",
    "label_categories = ['label_' + category for category in categories]\n",
    "analysis_categories = ['analysis_' + category for category in categories]\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "if os.path.exists(jsonl_file):\n",
    "    synthetic_df = pd.read_json(jsonl_file, lines=True)\n",
    "else:\n",
    "    synthetic_df = pd.DataFrame(\n",
    "        columns=[\"document_id\", \"position\"] + label_categories + analysis_categories + [\"inference_time\",\n",
    "                                                                                        \"prompt_tokens\",\n",
    "                                                                                        \"completion_tokens\",\n",
    "                                                                                        \"total_tokens\", \"text\", \"input\",\n",
    "                                                                                        \"output\"])\n",
    "\n",
    "synthetic_df = synthetic_df.dropna(subset=['text'])\n",
    "synthetic_df = synthetic_df[synthetic_df['text'] != '']\n",
    "\n",
    "synthetic_df = synthetic_df.drop_duplicates(subset='text', keep='first')\n",
    "synthetic_df"
   ],
   "id": "26a902303fa23b76",
   "execution_count": 83,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T18:41:22.372390Z",
     "start_time": "2024-06-30T18:41:22.370018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "categories = [category]\n",
    "\n",
    "size = 85  # Group of samples "
   ],
   "id": "e538daa4ce970c7d",
   "execution_count": 84,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T19:59:32.467688Z",
     "start_time": "2024-06-30T18:41:23.032411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "polarities = ['negative', 'neutral', 'neutral', 'positive']  # two bias and two unbiased\n",
    "\n",
    "total_records = size * len(polarities)\n",
    "\n",
    "for i in range(size):\n",
    "    for category in categories:\n",
    "\n",
    "        for polarity in polarities:\n",
    "            count = len(synthetic_df) + 1\n",
    "            formatted_percentage = \"{:.2f}%\".format((count / total_records) * 100)\n",
    "            print(\n",
    "                f'Generating synthetic for category {category}/{polarity}: {count}/{total_records} [ {formatted_percentage} ]',\n",
    "                end=' ')\n",
    "\n",
    "\n",
    "            position = random_job_title()\n",
    "            prompt, output, model, inference_time, prompt_tokens, completion_tokens, total_tokens = generate_text(position, [\n",
    "                f'{category}/{polarity}'])\n",
    "\n",
    "            text = find_first_between_tags(output, 'j')\n",
    "            analysis_age = find_first_between_tags(output, 'age')\n",
    "            analysis_disability = find_first_between_tags(output, 'disability')\n",
    "            analysis_feminine = find_first_between_tags(output, 'feminine')\n",
    "            analysis_masculine = find_first_between_tags(output, 'masculine')\n",
    "            analysis_racial = find_first_between_tags(output, 'racial')\n",
    "            analysis_sexuality = find_first_between_tags(output, 'sexuality')\n",
    "            analysis_general = find_first_between_tags(output, 'general')\n",
    "\n",
    "            timestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "            id = create_hash(output)\n",
    "            id = f\"{timestamp}:{polarity}:{id}\"\n",
    "            id_m = model.replace('/', ':')\n",
    "            data = {\n",
    "                \"id\": f'Synthetic:{id_m}:{id}',\n",
    "                \"document_id\": f'Synthetic:{id_m}:{id}',\n",
    "                \"position\": position\n",
    "            }\n",
    "\n",
    "            for label in label_categories:\n",
    "                data[label] = False\n",
    "\n",
    "            data[f'label_{category}'] = False if polarity == 'neutral' else True\n",
    "\n",
    "            data['inference_time'] = inference_time\n",
    "            data['prompt_tokens'] = prompt_tokens\n",
    "            data['completion_tokens'] = completion_tokens\n",
    "            data['total_tokens'] = total_tokens\n",
    "            data['model'] = id_m\n",
    "            data['text'] = text\n",
    "            data['analysis_age'] = analysis_age\n",
    "            data['analysis_disability'] = analysis_disability\n",
    "            data['analysis_feminine'] = analysis_feminine\n",
    "            data['analysis_masculine'] = analysis_masculine\n",
    "            data['analysis_racial'] = analysis_racial\n",
    "            data['analysis_sexuality'] = analysis_sexuality\n",
    "            data['analysis_general'] = analysis_general\n",
    "            data['input'] = prompt\n",
    "            data['output'] = output\n",
    "\n",
    "            with open(jsonl_file, 'a') as file:\n",
    "                if not os.stat(jsonl_file).st_size == 0:\n",
    "                    file.write('\\n')\n",
    "                file.write(json.dumps(data))\n",
    "\n",
    "            synthetic_df = pd.concat([synthetic_df, pd.DataFrame(data, index=[0])], ignore_index=True)\n",
    "            synthetic_df = synthetic_df.drop_duplicates(subset='text', keep='first')\n",
    "            synthetic_df.to_parquet(parquet_file, compression='gzip')\n",
    "\n",
    "            mean = synthetic_df['inference_time'].mean()\n",
    "            print(f'inference: {\"{:.2f}s\".format(inference_time)}; {\"{:.2f}s\".format(mean)} avg')\n",
    "\n",
    "        #break\n",
    "\n",
    "synthetic_df"
   ],
   "id": "ecbc61aad3248d4c",
   "execution_count": 85,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T18:00:38.688253Z",
     "start_time": "2024-06-30T18:00:38.679578Z"
    }
   },
   "cell_type": "code",
   "source": "synthetic_df",
   "id": "1ab049dc8b88b23a",
   "execution_count": 56,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:07:13.958070Z",
     "start_time": "2024-06-30T20:07:13.955098Z"
    }
   },
   "cell_type": "code",
   "source": "print(synthetic_df.tail(1)['output'].values[0])",
   "id": "2044d0456e9d9022",
   "execution_count": 86,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:07:38.374052Z",
     "start_time": "2024-06-30T20:07:38.371037Z"
    }
   },
   "cell_type": "code",
   "source": "print(synthetic_df.tail(1)[f'id'].values[0])",
   "id": "8fa2b44adc9d7da2",
   "execution_count": 87,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:07:41.229728Z",
     "start_time": "2024-06-30T20:07:41.226878Z"
    }
   },
   "cell_type": "code",
   "source": "print(synthetic_df.tail(1)[f'analysis_{category}'].values[0])",
   "id": "fd44d2bc3a7b5799",
   "execution_count": 88,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:07:42.906655Z",
     "start_time": "2024-06-30T20:07:42.903946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input = json.loads(synthetic_df.tail(1)[f'input'].values[0])[1]['content']\n",
    "print(input)"
   ],
   "id": "2fac6336f20e8a5e",
   "execution_count": 89,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "68544cfe8bdf5489",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (DCU AI)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
