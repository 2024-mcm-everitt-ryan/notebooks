{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:08:44.081342Z",
     "start_time": "2024-06-30T20:08:44.076429Z"
    }
   },
   "cell_type": "code",
   "source": "category = 'feminine'",
   "id": "7b30fa276a6009ea",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:08:49.385660Z",
     "start_time": "2024-06-30T20:08:49.382502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fix any tags that aren't getting closed.\n",
    "def fix_closing_tag(row):\n",
    "    if f'<{category}>' in row['output'] and f'</{category}>' not in row['output']:\n",
    "        return row['output'] + f'</{category}>'\n",
    "    else:\n",
    "        return row['output']\n",
    "\n",
    "def extract_tag_text(row):\n",
    "    output = row['output']\n",
    "    start_tag = f\"<{category}>\"\n",
    "    end_tag = f\"</{category}>\"\n",
    "\n",
    "    start_index = output.find(start_tag)\n",
    "    end_index = output.find(end_tag)\n",
    "\n",
    "    if start_index != -1 and end_index != -1:  # tags were found\n",
    "        start_index += len(start_tag)  # adjust to index after the start tag\n",
    "        result = output[start_index:end_index].strip()\n",
    "        result = result.replace('*', '')  # extract content between tags\n",
    "        return result\n",
    "\n",
    "    return None  # tags were not found or improperly formatted"
   ],
   "id": "83b818466701437c",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:08:58.673563Z",
     "start_time": "2024-06-30T20:08:58.270531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "output_dir = f'/home/teveritt/Datasets/2024-mcm-everitt-ryan/datasets/synthetic-job-postings/polarity-synthetic/{category}'\n",
    "jsonl_gpt4o_file = f'{output_dir}/polarity-synthetic-gpt4o.jsonl'\n",
    "jsonl_llama3b70_file = f'{output_dir}/polarity-synthetic-llama3b70.jsonl'\n",
    "parquet_file = f'{output_dir}/polarity-synthetic.parquet'\n",
    "\n",
    "df_gpt4o = pd.read_json(jsonl_gpt4o_file, lines=True)\n",
    "df_llama3b70 = pd.read_json(jsonl_llama3b70_file, lines=True)\n",
    "df = pd.concat([df_gpt4o, df_llama3b70])\n",
    "\n",
    "# These can introduce age bias\n",
    "df = df[~df.text.str.contains(\"10\\+? years\", case=False, na=False)]\n",
    "\n",
    "#df = df[~((df['model'] == 'gpt-4o-2024-05-13') & (df[f'label_{category}'] == False))] # gpt4o unbiased outputs had a high rate of bias.\n",
    "\n",
    "df['id'] = df['document_id']\n",
    "\n",
    "df['text'] = df['text'].str.replace('***', '', regex=False)\n",
    "df['text'] = df['text'].str.replace('**', '', regex=False)\n",
    "df['text'] = df['text'].str.replace('*', '-', regex=False)\n",
    "\n",
    "\n",
    "df['output'] = df.apply(fix_closing_tag, axis=1)\n",
    "df[f'analysis_{category}'] = df.apply(extract_tag_text, axis=1)\n",
    "\n",
    "for column in df.columns:\n",
    "    if column.startswith('analysis_') and column != f'analysis_{category}':\n",
    "        df[column] = ''\n",
    "    if column.startswith('label_') and column != f'label_{category}':\n",
    "        df[column] = False\n",
    "\n",
    "df"
   ],
   "id": "26a902303fa23b76",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:09:07.106167Z",
     "start_time": "2024-06-30T20:09:07.101917Z"
    }
   },
   "cell_type": "code",
   "source": "df['position'].unique()",
   "id": "1b1a90237c7157c9",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:09:08.865335Z",
     "start_time": "2024-06-30T20:09:08.862658Z"
    }
   },
   "cell_type": "code",
   "source": "df['model'].unique()",
   "id": "a99d9603b97740cc",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:09:11.362304Z",
     "start_time": "2024-06-30T20:09:11.357035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample = df[df[f'label_{category}'] == True].sample(1)\n",
    "\n",
    "print(sample['text'].values[0])\n",
    "print(f\"Biased: {sample[f'label_{category}'].values[0]}\")\n",
    "print(f\"ID: {sample['document_id'].values[0]}\")\n",
    "print(f\"Biased: {sample[f'analysis_{category}'].values[0]}\")"
   ],
   "id": "30a599ca8a33e1da",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:10:04.861565Z",
     "start_time": "2024-06-30T20:10:04.832200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(f'output-{category}.txt', 'w') as f:\n",
    "    for index, record in df.iterrows():\n",
    "        id = record['id']\n",
    "        analysis = record[f'analysis_{category}']\n",
    "        bias = record[f'label_{category}']\n",
    "        text = record['text']\n",
    "        f.write(f\"\\n====================================\\nBias: {bias} || {id}\\n{analysis}\\n------------------------------\\n\\n{text}\\n\\n\")\n"
   ],
   "id": "ebbabd0b628c521f",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:10:09.784185Z",
     "start_time": "2024-06-30T20:10:09.779104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for m in df['model'].unique():\n",
    "    biased = len(df[((df['model'] == m) & (df[f'label_{category}'] == True))])\n",
    "    not_biased = len(df[((df['model'] == m) & (df[f'label_{category}'] == False))])\n",
    "    print(f\"{m} || {bias + not_biased} || {bias} biased and {not_biased} not biased\")"
   ],
   "id": "d452ac84b8ab8c18",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:11:48.692730Z",
     "start_time": "2024-06-30T20:11:48.682040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_gold = pd.concat([\n",
    "   df[((df['model'] == 'meta-llama:Meta-Llama-3-70B-Instruct') & (df[f'label_{category}'] == True))].sample(85),\n",
    "   df[((df['model'] == 'gpt-4o-2024-05-13') & (df[f'label_{category}'] == True))].sample(85),\n",
    "   df[((df['model'] == 'meta-llama:Meta-Llama-3-70B-Instruct') & (df[f'label_{category}'] == False))].sample(85),\n",
    "   df[((df['model'] == 'gpt-4o-2024-05-13') & (df[f'label_{category}'] == False))].sample(85),\n",
    "])\n",
    "df_gold[df_gold[f'label_{category}'] == True].value_counts('model')"
   ],
   "id": "c831fe811d35646c",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:11:50.585057Z",
     "start_time": "2024-06-30T20:11:50.579558Z"
    }
   },
   "cell_type": "code",
   "source": "df_gold[df_gold[f'label_{category}'] == False].value_counts('model')",
   "id": "b1f7343021f5da53",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:15:19.784599Z",
     "start_time": "2024-06-30T20:15:19.773813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#with open(f'gold_ids_{category}.txt', 'w') as f:\n",
    "#    for index, record in df_gold.iterrows():\n",
    "#        id = record['id']\n",
    "#        f.write(f\"{id}\\n\")"
   ],
   "id": "89de39e6683f5199",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:15:20.699617Z",
     "start_time": "2024-06-30T20:15:20.656352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#with open(f'review-{category}.txt', 'w') as f:\n",
    "#    for index, record in df_gold[df_gold[f'label_{category}']==True].iterrows():\n",
    "#        id = record['id']\n",
    "#        analysis = record[f'analysis_{category}']\n",
    "#        bias = record[f'label_{category}']\n",
    "#        text = record['text']\n",
    "#        f.write(f\"\\n====================================\\nBias: {bias} || {id}\\n{analysis}\\n------------------------------\\n\\n{text}\\n\\n\")\n",
    "#    for index, record in df_gold[df_gold[f'label_{category}']==False].iterrows():\n",
    "#        id = record['id']\n",
    "#        analysis = record[f'analysis_{category}']\n",
    "#        bias = record[f'label_{category}']\n",
    "#        text = record['text']\n",
    "#        f.write(f\"\\n====================================\\nBias: {bias} || {id}\\n{analysis}\\n------------------------------\\n\\n{text}\\n\\n\")"
   ],
   "id": "6412019b65bc3912",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:15:42.117545Z",
     "start_time": "2024-06-30T20:15:42.102767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ids = []\n",
    "\n",
    "with open(f\"gold_ids_{category}.txt\", \"r\") as file:\n",
    "    ids = file.read().splitlines()\n",
    "\n",
    "df_gold = df[df['id'].isin(ids)]\n",
    "df_gold"
   ],
   "id": "ba06bb92494f60b9",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:15:45.965478Z",
     "start_time": "2024-06-30T20:15:45.960506Z"
    }
   },
   "cell_type": "code",
   "source": "df_gold.value_counts(f'label_{category}')",
   "id": "36dec6ca92591c09",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:15:53.786255Z",
     "start_time": "2024-06-30T20:15:53.701896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "label_columns = [col for col in df_gold.columns if col.startswith('label_')]\n",
    "analysis_columns = [col for col in df_gold.columns if col.startswith('analysis_')]\n",
    "\n",
    "#df['notes'] = df['notes'].fillna('')\n",
    "\n",
    "df_gold['verified'] = True\n",
    "df_gold['synthetic'] = True\n",
    "\n",
    "columns = ['id']\n",
    "for c in ['age','disability','masculine','feminine','racial','sexuality','general']:\n",
    "    columns.append(f'label_{c}')\n",
    "    columns.append(f'analysis_{c}')\n",
    "    \n",
    "columns += ['verified', 'synthetic', 'text', 'metadata']\n",
    "\n",
    "metadata_columns = ['position', 'inference_time','prompt_tokens', 'completion_tokens', 'total_tokens', 'model', 'input', 'output']\n",
    "df_gold['metadata'] = df_gold.apply(lambda row: json.dumps(row[metadata_columns].to_dict()), axis=1)\n",
    "\n",
    "df_gold = df_gold[columns]\n",
    "df_gold"
   ],
   "id": "2f4c5247692b10a2",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:15:57.299228Z",
     "start_time": "2024-06-30T20:15:57.295445Z"
    }
   },
   "cell_type": "code",
   "source": "df_gold.columns",
   "id": "142ec644a006e89e",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:15:59.459850Z",
     "start_time": "2024-06-30T20:15:59.456958Z"
    }
   },
   "cell_type": "code",
   "source": "df_gold.head(1)['metadata'].values[0]",
   "id": "fbf65c9c3c027711",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:16:18.280699Z",
     "start_time": "2024-06-30T20:16:17.723322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split(dataframe):\n",
    "    df_train, df_80 = train_test_split(dataframe, test_size=0.8, random_state=2024)\n",
    "    df_val, df_test = train_test_split(df_80, test_size=0.5, random_state=2024)\n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "df_gold_bias = df_gold[df_gold[f'label_{category}'] == True]\n",
    "df_gold_unbias = df_gold[df_gold[f'label_{category}'] == False]\n",
    "\n",
    "df_bias_train, df_bias_val, df_bias_test = split(df_gold_bias)\n",
    "df_unbias_train, df_unbias_val, df_unbias_test = split(df_gold_unbias)\n",
    "\n",
    "df_train = pd.concat([df_bias_train,df_unbias_train])\n",
    "df_val = pd.concat([df_bias_val,df_unbias_val])\n",
    "df_test = pd.concat([df_bias_test,df_unbias_test])\n",
    "\n",
    "df_train.to_parquet(f'synthetic-{category}-train.parquet', compression='gzip')\n",
    "df_val.to_parquet(f'synthetic-{category}-val.parquet', compression='gzip')\n",
    "df_test.to_parquet(f'synthetic-{category}-test.parquet', compression='gzip')"
   ],
   "id": "e0990cbceefa8abd",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:16:21.192012Z",
     "start_time": "2024-06-30T20:16:21.190423Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3d4062bff9bd49a6",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T20:16:21.645182Z",
     "start_time": "2024-06-30T20:16:21.641949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Longest phrase\n",
    "longest_text = df_gold['text'].apply(lambda x: (len(x), x)).max()[1]\n",
    "print(longest_text)"
   ],
   "id": "b94db31a27d932d4",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:06:42.689539Z",
     "start_time": "2024-06-27T19:06:42.685357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "def print_max_tokens(model_id):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, add_prefix_space=True)\n",
    "    max_tokens = len(tokenizer.encode(longest_text))\n",
    "    print(f\"Max '{model_id}' tokens: {max_tokens}\")\n",
    "\n",
    "\n",
    "def print_encode_decoded(model_id, longest_text):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, add_prefix_space=True)\n",
    "    encoded_tokens = tokenizer.encode(longest_text)\n",
    "    print(f\"Tokens: {encoded_tokens}\")\n",
    "    print(f\"Decoded tokens: {tokenizer.decode(encoded_tokens)}\")\n",
    "\n",
    "\n",
    "def print_tokens(model_id, longest_text):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, add_prefix_space=True)\n",
    "    tokens = tokenizer.tokenize(longest_text)\n",
    "    print(f\"Tokens: {tokens}\")\n"
   ],
   "id": "a832d085734ac7e5",
   "execution_count": 132,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:06:45.736444Z",
     "start_time": "2024-06-27T19:06:44.824369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_char = len(longest_text)\n",
    "max_words = len(longest_text.split())\n",
    "\n",
    "print(f'Max characters: {max_char}')\n",
    "print(f'Max words: {max_words}')\n",
    "for model in ['roberta-base', 'bert-base-uncased', 'microsoft/deberta-v3-small']:\n",
    "    print_max_tokens(model)\n"
   ],
   "id": "a54d9b5d5a70b109",
   "execution_count": 133,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "2044d0456e9d9022",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (DCU AI)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
