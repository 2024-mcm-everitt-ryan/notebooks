{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T00:02:29.857818Z",
     "start_time": "2024-06-29T00:02:29.853952Z"
    }
   },
   "cell_type": "code",
   "source": "category = 'general'",
   "id": "585e87ba2b57864a",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:50:49.569885Z",
     "start_time": "2024-06-29T09:50:49.566350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import huggingface_hub\n",
    "from openai import OpenAI\n",
    "\n",
    "temperature = 0.8\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    return content.rstrip('\\n')\n",
    "\n",
    "use_gpt_model = False\n",
    "\n",
    "if use_gpt_model:\n",
    "    model = 'gpt-4o'\n",
    "    model_shortname = 'gpt4o'\n",
    "    base_url = None\n",
    "    api_key=read_file(\"/home/teveritt/OpenAI-API-DCU-AI.key\")\n",
    "else:\n",
    "    model = 'meta-llama/Meta-Llama-3-70B-Instruct'\n",
    "    model_shortname = 'llama3b70'\n",
    "    base_url = f\"https://api-inference.huggingface.co/models/{model}/v1/\"\n",
    "    #base_url='https://ylzx7jabydlt5hql.us-east-1.aws.endpoints.huggingface.cloud/v1/'\n",
    "    api_key=huggingface_hub.get_token()\n",
    "\n",
    "def openai_chat(messages):\n",
    "    client = OpenAI(base_url=base_url, api_key=api_key)\n",
    "\n",
    "    return client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=messages,\n",
    "        stream=False,\n",
    "        max_tokens=1525\n",
    "    )"
   ],
   "id": "f425a1a02b015fd7",
   "execution_count": 73,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:50:50.182430Z",
     "start_time": "2024-06-29T09:50:50.177791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fetch a job title from job-phrase-list.csv\n",
    "# Original source of list: https://github.com/microsoft/LUIS-Samples/blob/master/documentation-samples/tutorials/job-phrase-list.csv\n",
    "# https://www.kaggle.com/datasets/estasney/job-titles?select=titles.csv\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def get_job_titles():\n",
    "    titles = set()\n",
    "    with open(\"microsoft-LUIS-job-phrase-list.csv\", \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            titles.add(line.replace(',\\n', '').replace('\\n', ''))\n",
    "\n",
    "    #kaggle_titles = pd.read_csv('kaggle-titles.csv')\n",
    "    #for col in kaggle_titles.columns:\n",
    "    #    if col.startswith('Title_'):\n",
    "    #        titles.update(kaggle_titles[col].dropna().unique())\n",
    "\n",
    "    return list(titles)\n",
    "\n",
    "\n",
    "positions = get_job_titles()\n",
    "\n",
    "\n",
    "def random_job_title():\n",
    "    return random.choice(positions)\n",
    "\n",
    "\n",
    "print(f'Positions: {len(positions)}')"
   ],
   "id": "f6ca3016e760eb74",
   "execution_count": 74,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:50:51.452508Z",
     "start_time": "2024-06-29T09:50:51.450036Z"
    }
   },
   "cell_type": "code",
   "source": "random_job_title()",
   "id": "dffdde008fc9d43c",
   "execution_count": 75,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:50:52.634144Z",
     "start_time": "2024-06-29T09:50:52.631280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_definition(category):\n",
    "    with open(f\"definitions/{category}.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def random_phrases(category, polarity, num_lines=None):\n",
    "    with open(f\"polarity-phrases/{category}-{polarity}.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "        all_lines = [line.rstrip('\\n') for line in f.readlines()]  # remove \\n\n",
    "        all_lines = [line if line.endswith('.') else line + '.' for line in all_lines]  # add . at the end\n",
    "        if num_lines is not None:\n",
    "            return random.sample(all_lines, num_lines)\n",
    "        else:\n",
    "            return all_lines"
   ],
   "id": "4fbb04f8a37d6cc9",
   "execution_count": 76,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:50:53.453694Z",
     "start_time": "2024-06-29T09:50:53.451141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system = f\"\"\"\n",
    "This GPT generates 200 word synthetic job postings across seven categories: age, disability, feminine, masculine, racial, sexuality, and general. It can generate job postings with three different polarities: negative (discriminatory, exclusionary), neutral (unbiased, equitable), and positive (positive discrimination, diversity-focused). The job post builder adheres to the following definitions:\n",
    "\n",
    "- Age bias: Language that subtly favours certain age groups, such as terms implying energy or modernity for younger candidates, or experience and wisdom for older candidates.\n",
    "\n",
    "- Disability bias: Terms or requirements that subtly exclude individuals based on disabilities, like ableist terms implying physical traits or lack of language on reasonable accommodations.\n",
    "\n",
    "- Feminine bias: Language that subtly favours female candidates, including gender-coded words, domestic metaphors, and gendered job titles and pronouns.\n",
    "\n",
    "- General bias: Subtle language favouring or disadvantaging candidates based on characteristics like socio-economic status, educational background, mental health, gender roles, veteran status, criminal history, or political beliefs.\n",
    "\n",
    "- Masculine bias: Language that subtly favours male candidates, including gender-coded words, sports or military metaphors, and gendered job titles and pronouns.\n",
    "\n",
    "- Racial bias: Language subtly favouring certain racial groups or excluding others, like racially insensitive terms, exclusionary phrases, and assumptions about linguistic proficiency.\n",
    "\n",
    "- Sexuality bias: Language subtly favouring certain sexual orientations or gender identities, including heteronormative terms, outdated terminology, lack of recognition of diverse family structures, assumptions about gender identity, and non-inclusive pronouns.\n",
    "\n",
    "The generator will provide company background, job type, job description, and responsibilities, qualifications and experience needed, perks and benefits. \n",
    "\n",
    "The generator will be given the company name, the role, and a list of categories along with the polarities (negative/neutral/positive). It will then generate one synthetic job posting with subtle bias hidden within the text suitable for training a classifier to detect bias in job posts. The subtle bias should not be similar to each other and obviously bias. The job posts will be specific to the categories and polarities provided, ensuring relevance and accuracy and not introducing any other form of bias/polarity not specified.\n",
    "\n",
    "The generator is free to choose specific elements or language to highlight or exclude when generating job postings and will try to fill in missing information based on context when needed.\n",
    "\n",
    "The GPT should maintain a formal and professional tone when interacting with users.\n",
    "\"\"\""
   ],
   "id": "cf2693a2b21461e8",
   "execution_count": 77,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:50:54.244524Z",
     "start_time": "2024-06-29T09:50:54.241291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system2 = f\"\"\"\n",
    "This GPT generates 200-word synthetic job postings across seven categories: age, disability, feminine, masculine, racial, sexuality, and general. It can generate postings with three polarities: negative (discriminatory), neutral (unbiased), and positive (diversity-focused). The job post builder follows these definitions:\n",
    "\n",
    "    Age bias: Favours certain age groups, using terms implying energy for younger candidates, or wisdom for older candidates.\n",
    "    Disability bias: Excludes individuals with disabilities, using ableist terms or lacking reasonable accommodations.\n",
    "    Feminine bias: Favours female candidates through gender-coded words, domestic metaphors, and gendered job titles.\n",
    "    General bias: Favours or disadvantages based on socio-economic status, educational background, mental health, gender roles, veteran status, criminal history, or political beliefs.\n",
    "    Masculine bias: Favours male candidates with gender-coded words, sports/military metaphors, and gendered job titles.\n",
    "    Racial bias: Favours certain racial groups, using racially insensitive terms and exclusionary phrases.\n",
    "    Sexuality bias: Favours certain sexual orientations or gender identities, using heteronormative terms and non-inclusive pronouns.\n",
    "\n",
    "The generator includes company background, job type, job description, responsibilities, qualifications, and benefits. Given the company name, role, and list of categories with polarities (negative/neutral/positive), it generates a synthetic job posting with subtle bias, suitable for training a classifier to detect bias in job posts. Subtle biases should not be obvious or repetitive.'\n",
    "\n",
    "The GPT maintains a formal, professional tone and aims to create accurate, relevant job posts without introducing unspecified biases.\n",
    "\"\"\""
   ],
   "id": "48f7c8ce22c000a2",
   "execution_count": 78,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:50:55.246741Z",
     "start_time": "2024-06-29T09:50:55.189934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from faker import Faker\n",
    "\n",
    "bias_polarities = {\n",
    "    'age/positive': 'Age: Positive, discouraging younger candidates from considering applying',\n",
    "    'age/negative': 'Age: Negative, discouraging older candidates from considering applying.',\n",
    "    'age/neutral': 'Age: Neutral, language is unbiased and does not favour any age group.',\n",
    "\n",
    "    'disability/negative': 'Disability: Negative, discourages candidates with disabilities, including neurodiverse individuals, from applying. This can occur through the inclusion of non-essential physical requirements, complex words, extra-long sentences, or lengthy lists of essential requirements.',\n",
    "    'disability/neutral': 'Disability: Neutral, language that neither disadvantage nor give undue preference to candidates with disabilities. This approach focuses on inclusivity by ensuring job requirements are essential and relevant, avoiding unnecessary physical demands, and using clear, straightforward language.',\n",
    "    'disability/positive': 'Disability: Positive, language that give undue preference to candidates with disabilities, often to fulfil diversity quotas or appear inclusive. This can result in tokenism, where individuals with disabilities are selected primarily based on their protected characteristics rather than their qualifications or experience.',\n",
    "\n",
    "    'feminine/negative': 'Feminine: Negative, discouraging non-female candidates from considering applying.',\n",
    "    'feminine/neutral': 'Feminine: Neutral, language is unbiased and does not favour any gender.',\n",
    "    'feminine/positive': 'Feminine: Positive, language encourages female candidates to apply, potentially making it appear that non-females won’t be considered.',\n",
    "\n",
    "    'general/negative': 'General: Negative, involves language that subtly discriminates against individuals based on socio-economic status, educational background, mental health status, gender roles, veteran status, criminal history, or political beliefs. This bias is often reflected through unprofessional, outdated, or non-transparent language that discourages certain groups from applying and perpetuates inequality and exclusion in the hiring process.',\n",
    "    'general/neutral': 'General: Neutral bias in job descriptions involves using inclusive, professional, and transparent language that avoids discriminating against individuals based on socio-economic status, educational background, mental health status, gender roles, veteran status, criminal history, or political beliefs. The language is unbiased and does not favour or disadvantage any group, ensuring job postings are welcoming to all candidates and promoting fairness, equality, and inclusivity.',\n",
    "\n",
    "    'masculine/negative': 'Masculine: Negative, discouraging non-male candidates from considering applying.',\n",
    "    'masculine/neutral': 'Masculine: Neutral, language is unbiased and does not favour any gender.',\n",
    "    'masculine/positive': 'Masculine: Positive, language encourages male candidates to apply, potentially making it appear that non-males won’t be considered.',\n",
    "\n",
    "    'racial/negative': 'Racial: Negative, discouraging candidates of certain racial groups from considering applying.',\n",
    "    'racial/neutral': 'Racial: Neutral, language is unbiased and does not favour any racial group.',\n",
    "    'racial/positive': 'Racial: Positive, language promotes racial diversity and encourages candidates from various racial backgrounds and minority groups to apply, potentially making it appear that certain racial groups or non-minority groups won’t be considered.',\n",
    "\n",
    "    'sexuality/negative': 'Sexuality: Negative, discouraging non-heteronormative candidates from considering applying.',\n",
    "    'sexuality/neutral': 'Sexuality: Neutral, language is unbiased and does not favour any sexual orientation or gender identity.',\n",
    "    'sexuality/positive': 'Sexuality: Positive, language encourages individuals of diverse sexual orientations and gender identities to apply, potentially making it appear that certain orientations or identities won’t be considered.'\n",
    "}\n",
    "\n",
    "categories = ['age', 'disability', 'feminine', 'masculine', 'racial', 'sexuality', 'general']\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "\n",
    "def get_inputs(position, inject_bias_types):\n",
    "    user_input = f\"\"\"Company: {fake.company()}\n",
    "Role: {position}\n",
    "Bias/Polarities:\"\"\"\n",
    "\n",
    "    for idx, type in enumerate(inject_bias_types):\n",
    "        category = type.split('/')[-2]\n",
    "        polarity = type.split('/')[-1]\n",
    "        user_input += f\"\\n  {idx + 1}. {bias_polarities[type]} Examples are:\"\n",
    "        for phrase in random_phrases(category, polarity, 5):\n",
    "            user_input += f\"\\n    - {phrase}\"\n",
    "\n",
    "    return user_input\n",
    "\n",
    "\n",
    "def get_output_format(inject_bias_types):\n",
    "    output_format = \"\"\"Review the job posting to make sure it has not introduced any other form of bias not specified and the rationale matches the bias/polarities specified. Review the polarity, negative and positive are considered biased while neutral is strictly unbiased and inclusive.  Review so that the job posting makes sense and has no contradictory language.  \"\"\"\n",
    "    \n",
    "    output_format += \"\"\"Unless one of the examples says to use lack of transparency for salary/benefits/offer (e.g. competitive salary), always review the salary/benefits/offer and if there is a lack of transparency (e.g. Competitive pay/salary), then adjust it to add more transparency (e.g \"We are committed to fair and equitable pay practices. The salary for this position ranges from <GPT fills this in> to <GPT fills this in>, based on your experience and skills\").  Pick one of global currency reserves when mentioning salary or revenue.\"\"\"\n",
    "    \n",
    "    \n",
    "    output_format += \"\"\"Once reviewed and corrected, output with the following format (tag names are lowercase):\n",
    "  1. Wrap the job posting within the <j>...</j> tag.\"\"\"\n",
    "    for idx, type in enumerate(inject_bias_types):\n",
    "        category = type.split('/')[-2]\n",
    "        output_format += f\"\\n  {idx + 2}. Summarise, using third-person, the {category} rationale within one <{category}>...</{category}> tag.\"\n",
    "\n",
    "    return output_format\n",
    "\n",
    "\n",
    "def generate_text(position, inject_bias_types):\n",
    "    m = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system\n",
    "        }, {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": get_inputs(position, inject_bias_types)\n",
    "        }, {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"I have the job posting ready, how should I respond?\"\n",
    "        }, {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": get_output_format(inject_bias_types),\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    output = openai_chat(m)\n",
    "    inference_time = time.time() - start_time\n",
    "\n",
    "    prompt_tokens = output.usage.prompt_tokens\n",
    "    completion_tokens = output.usage.completion_tokens\n",
    "    total_tokens = output.usage.total_tokens\n",
    "    content = output.choices[0].message.content\n",
    "\n",
    "    #return json.dumps(m), chat(m)\n",
    "    return json.dumps(m), content, output.model, inference_time, prompt_tokens, completion_tokens, total_tokens"
   ],
   "id": "a45a28bfef073d72",
   "execution_count": 79,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:50:56.622531Z",
     "start_time": "2024-06-29T09:50:56.619012Z"
    }
   },
   "cell_type": "code",
   "source": "print(get_inputs(random_job_title(), [f'{category}/negative', f'{category}/neutral']))",
   "id": "a94c87dda49d3705",
   "execution_count": 80,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:46:18.490207Z",
     "start_time": "2024-06-29T09:46:18.487328Z"
    }
   },
   "cell_type": "code",
   "source": "print(get_output_format([f'{category}/negative']))",
   "id": "e48803966f8ac21b",
   "execution_count": 60,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:46:27.269322Z",
     "start_time": "2024-06-29T09:46:27.266130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import hashlib\n",
    "\n",
    "\n",
    "def create_hash(input_string):\n",
    "    return hashlib.sha256(input_string.encode()).hexdigest()[:10]\n",
    "\n",
    "\n",
    "def lowercase_tags(text):\n",
    "    tags = re.findall(r'<\\/?\\w+', text)\n",
    "    for tag in tags:\n",
    "        text = text.replace(tag, tag.lower())\n",
    "    return text\n",
    "\n",
    "def find_first_between_tags(file_content, tag):\n",
    "    # Fix missing closing tag\n",
    "    if f'<{tag}>' in file_content and f'</{tag}>' not in file_content:\n",
    "        file_content =  file_content + f'</{tag}>'\n",
    "    \n",
    "    start_tag = f\"<{tag}>\"\n",
    "    end_tag = f\"</{tag}>\"\n",
    "\n",
    "    start_index = file_content.find(start_tag)\n",
    "    end_index = file_content.find(end_tag)\n",
    "\n",
    "    if start_index != -1 and end_index != -1:  # tags were found\n",
    "        start_index += len(start_tag)  # adjust to index after the start tag\n",
    "        result = file_content[start_index:end_index].strip()\n",
    "        result = result.replace('*', '')  # extract content between tags\n",
    "        return result\n",
    "\n",
    "    return None  # tags were not found or improperly formatted"
   ],
   "id": "68721f6541d0b03e",
   "execution_count": 61,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:51:05.739746Z",
     "start_time": "2024-06-29T09:51:05.712737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "output_dir = f'/home/teveritt/Datasets/2024-mcm-everitt-ryan/datasets/synthetic-job-postings/polarity-synthetic/{category}'\n",
    "jsonl_file = f'{output_dir}/polarity-synthetic-{model_shortname}.jsonl'\n",
    "parquet_file = f'{output_dir}/polarity-synthetic-{model_shortname}.parquet'\n",
    "\n",
    "label_categories = ['label_' + category for category in categories]\n",
    "analysis_categories = ['analysis_' + category for category in categories]\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "if os.path.exists(jsonl_file):\n",
    "    synthetic_df = pd.read_json(jsonl_file, lines=True)\n",
    "else:\n",
    "    synthetic_df = pd.DataFrame(\n",
    "        columns=[\"document_id\", \"position\"] + label_categories + analysis_categories + [\"inference_time\",\n",
    "                                                                                        \"prompt_tokens\",\n",
    "                                                                                        \"completion_tokens\",\n",
    "                                                                                        \"total_tokens\", \"text\", \"input\",\n",
    "                                                                                        \"output\"])\n",
    "\n",
    "synthetic_df = synthetic_df.dropna(subset=['text'])\n",
    "synthetic_df = synthetic_df[synthetic_df['text'] != '']\n",
    "\n",
    "synthetic_df = synthetic_df.drop_duplicates(subset='text', keep='first')\n",
    "synthetic_df"
   ],
   "id": "26a902303fa23b76",
   "execution_count": 81,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:48:35.137989Z",
     "start_time": "2024-06-29T09:48:35.135543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "categories = [category]\n",
    "\n",
    "size = 60  # Group of samples "
   ],
   "id": "e538daa4ce970c7d",
   "execution_count": 71,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:50:16.831463Z",
     "start_time": "2024-06-29T09:48:36.166338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "polarities = ['negative', 'neutral']  # two bias and two unbiased\n",
    "\n",
    "total_records = size * len(polarities)\n",
    "\n",
    "for i in range(size):\n",
    "    for category in categories:\n",
    "\n",
    "        for polarity in polarities:\n",
    "            count = len(synthetic_df) + 1\n",
    "            formatted_percentage = \"{:.2f}%\".format((count / total_records) * 100)\n",
    "            print(\n",
    "                f'Generating synthetic for category {category}/{polarity}: {count}/{total_records} [ {formatted_percentage} ]',\n",
    "                end=' ')\n",
    "\n",
    "\n",
    "            position = random_job_title()\n",
    "            prompt, output, model, inference_time, prompt_tokens, completion_tokens, total_tokens = generate_text(position, [\n",
    "                f'{category}/{polarity}'])\n",
    "\n",
    "            text = find_first_between_tags(output, 'j')\n",
    "            analysis_age = find_first_between_tags(output, 'age')\n",
    "            analysis_disability = find_first_between_tags(output, 'disability')\n",
    "            analysis_feminine = find_first_between_tags(output, 'feminine')\n",
    "            analysis_masculine = find_first_between_tags(output, 'masculine')\n",
    "            analysis_racial = find_first_between_tags(output, 'racial')\n",
    "            analysis_sexuality = find_first_between_tags(output, 'sexuality')\n",
    "            analysis_general = find_first_between_tags(output, 'general')\n",
    "\n",
    "            timestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "            id = create_hash(output)\n",
    "            id = f\"{timestamp}:{polarity}:{id}\"\n",
    "            id_m = model.replace('/', ':')\n",
    "            data = {\n",
    "                \"id\": f'Synthetic:{id_m}:{id}',\n",
    "                \"document_id\": f'Synthetic:{id_m}:{id}',\n",
    "                \"position\": position\n",
    "            }\n",
    "\n",
    "            for label in label_categories:\n",
    "                data[label] = False\n",
    "\n",
    "            data[f'label_{category}'] = False if polarity == 'neutral' else True\n",
    "\n",
    "            data['inference_time'] = inference_time\n",
    "            data['prompt_tokens'] = prompt_tokens\n",
    "            data['completion_tokens'] = completion_tokens\n",
    "            data['total_tokens'] = total_tokens\n",
    "            data['model'] = id_m\n",
    "            data['text'] = text\n",
    "            data['analysis_age'] = analysis_age\n",
    "            data['analysis_disability'] = analysis_disability\n",
    "            data['analysis_feminine'] = analysis_feminine\n",
    "            data['analysis_masculine'] = analysis_masculine\n",
    "            data['analysis_racial'] = analysis_racial\n",
    "            data['analysis_sexuality'] = analysis_sexuality\n",
    "            data['analysis_general'] = analysis_general\n",
    "            data['input'] = prompt\n",
    "            data['output'] = output\n",
    "\n",
    "            with open(jsonl_file, 'a') as file:\n",
    "                if not os.stat(jsonl_file).st_size == 0:\n",
    "                    file.write('\\n')\n",
    "                file.write(json.dumps(data))\n",
    "\n",
    "            synthetic_df = pd.concat([synthetic_df, pd.DataFrame(data, index=[0])], ignore_index=True)\n",
    "            synthetic_df = synthetic_df.drop_duplicates(subset='text', keep='first')\n",
    "            synthetic_df.to_parquet(parquet_file, compression='gzip')\n",
    "\n",
    "            mean = synthetic_df['inference_time'].mean()\n",
    "            print(f'inference: {\"{:.2f}s\".format(inference_time)}; {\"{:.2f}s\".format(mean)} avg')\n",
    "\n",
    "        #break\n",
    "\n",
    "synthetic_df"
   ],
   "id": "ecbc61aad3248d4c",
   "execution_count": 72,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T12:34:33.453747Z",
     "start_time": "2024-06-28T12:34:33.441569Z"
    }
   },
   "cell_type": "code",
   "source": "synthetic_df",
   "id": "1ab049dc8b88b23a",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:47:48.092149Z",
     "start_time": "2024-06-29T09:47:48.089393Z"
    }
   },
   "cell_type": "code",
   "source": "print(synthetic_df.tail(1)['text'].values[0])",
   "id": "2044d0456e9d9022",
   "execution_count": 69,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T09:47:51.072314Z",
     "start_time": "2024-06-29T09:47:51.069401Z"
    }
   },
   "cell_type": "code",
   "source": "print(synthetic_df.tail(1)[f'analysis_{category}'].values[0])",
   "id": "fd44d2bc3a7b5799",
   "execution_count": 70,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "2fac6336f20e8a5e",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (DCU AI)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
