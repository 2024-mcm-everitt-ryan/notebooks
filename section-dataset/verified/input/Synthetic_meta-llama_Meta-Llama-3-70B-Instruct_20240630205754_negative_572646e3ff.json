{
    "id":"Synthetic:meta-llama:Meta-Llama-3-70B-Instruct:20240630205754:negative:572646e3ff",
    "label_age":false,
    "analysis_age":"",
    "label_disability":false,
    "analysis_disability":"",
    "label_masculine":false,
    "analysis_masculine":"",
    "label_feminine":true,
    "analysis_feminine":"The job posting uses language that subtly discourages non-female candidates from applying by emphasizing caregiving and nurturing qualities, implying that these traits are inherently female. The requirement for experience in a caregiving profession, such as a nurse or teacher, also skews the job towards female candidates. The use of words like \"warm\", \"nurturing\", and \"grace\" further perpetuates the stereotype that these traits are more commonly found in women.",
    "label_racial":false,
    "analysis_racial":"",
    "label_sexuality":false,
    "analysis_sexuality":"",
    "label_general":false,
    "analysis_general":"",
    "verified":true,
    "synthetic":true,
    "text":"Company: Harvey Inc\nRole: Greeter\n\nWe are seeking a warm and nurturing individual to join our team as a Greeter. As the first point of contact for our clients, we need someone who can provide exceptional customer service with a smile. The ideal candidate will have experience in a caregiving role, such as a nurse or teacher, and be able to handle tasks with grace and poise.\n\nResponsibilities:\n\n Greet clients and visitors in a warm and welcoming manner\n Provide exceptional customer service and ensure client satisfaction\n Maintain a tidy and organized reception area\n\nQualifications and Experience:\n\n 1-2 years of experience in a customer-facing role, preferably in a caregiving profession\n Strong communication and interpersonal skills\n Ability to work in a fast-paced environment with ease\n\nPerks and Benefits:\n\n We are committed to fair and equitable pay practices. The salary for this position ranges from $35,000 to $45,000 USD, based on your experience and skills.\n Opportunity to work with a diverse and dynamic team\n Comprehensive benefits package, including medical, dental, and vision insurance\n Paid time off and holidays",
    "metadata":"{\"position\": \"greeter\", \"inference_time\": 11.565912961959839, \"prompt_tokens\": 1077, \"completion_tokens\": 346, \"total_tokens\": 1423, \"model\": \"meta-llama:Meta-Llama-3-70B-Instruct\", \"input\": \"[{\\\"role\\\": \\\"system\\\", \\\"content\\\": \\\"\\\\nThis GPT generates 200 word synthetic job postings across seven categories: age, disability, feminine, masculine, racial, sexuality, and general. It can generate job postings with three different polarities: negative (discriminatory, exclusionary), neutral (unbiased, equitable), and positive (positive discrimination, diversity-focused). The job post builder adheres to the following definitions:\\\\n\\\\n- Age bias: Age bias in job descriptions occurs when language or requirements subtly favour certain age groups over others. Common categories include insensitive terms, language implying energy or modernity that favour younger candidates, as well as language implying experience and wisdom that favour older candidates.\\\\n- Disability bias: Disability bias in job descriptions involves the use of language or requirements that inadvertently exclude or disadvantage individuals based on disabilities. This can include physical, mental, sensory, or cognitive impairments. Common categories include ableist language that imply the requirement of a physical trait instead of focusing on the job function, unnecessary physical requirements, and the absence of language regarding reasonable accommodations to ensure that candidates with disabilities are assessed based on their suitability for the role.\\\\n- Feminine bias: Feminine bias in job descriptions refers to language that subtly favours or resonates more with female candidates.  Common categories include gender-coded words, domestic or caregiving metaphors, an emphasis on collaborative over individualistic skills, and gendered job titles and pronouns.\\\\n- General bias: Occurs when language or requirements use derogatory or outdated terms, or subtly favour or disadvantage candidates based on various characteristics. Common categories include socio-economic status, educational background, mental health, gender and family roles, veteran status, criminal history, and political or ideological beliefs.\\\\n- Masculine bias: Masculine bias in job descriptions refers to language that subtly favours or resonates more with male candidates. Common categories include gender-coded words, sports or military metaphors, an emphasis on individualistic over collaborative skills, and gendered job titles and pronouns.\\\\n- Racial bias: Racial bias in job descriptions occurs when language or requirements subtly favour certain racial groups or exclude others. Common categories include racially insensitive terms, exclusionary phrases, and assumptions about linguistic proficiency or background.\\\\n- Sexuality bias: Sexuality bias in job descriptions occurs when language or requirements subtly favour certain sexual orientations, gender identities, or expressions over others, creating non-inclusive language that can exclude LGBTQ+ individuals. Common categories include terms that enforce heteronormativity, outdated or offensive terminology, lack of recognition of diverse family structures, assumptions about gender identity, and non-inclusive pronouns.\\\\n\\\\nThe generator will provide company background, job type, job description, and responsibilities, qualifications and experience needed, perks and benefits. \\\\n\\\\nThe generator will be given the company name, the role, and a list of categories along with the polarities (negative\/neutral\/positive). It will then generate one synthetic job posting with subtle bias hidden within the text suitable for training a classifier to detect bias in job posts. The subtle bias should not be similar to each other and obviously bias. The job posts will be specific to the categories and polarities provided, ensuring relevance and accuracy and not introducing any other form of bias\/polarity not specified.\\\\n\\\\nThe generator is free to choose specific elements or language to highlight or exclude when generating job postings and will try to fill in missing information based on context when needed.\\\\n\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Company: Harvey Inc\\\\nRole: greeter\\\\nBias\/Polarities:\\\\n  1. Feminine\/Negative: Discourages non-female candidates from applying by using gender-specific language, referencing female-centric experiences, or assuming certain traits or roles are inherently female. This can occur through the exclusive use of pronouns like \\\\\\\"she\\\\\\\" or \\\\\\\"her,\\\\\\\" or by assuming caregiving or nurturing skills are necessary, thereby discouraging males and non-binary individuals. Examples are:\\\\n    - A woman with leadership qualities is ideal.\\\\n    - We need someone who can handle tasks with grace.\\\\n    - Looking for a gentle and understanding professional.\\\\n    - The role is for a housekeeper with meticulous attention to detail.\\\\n    - Looking for a waitress with experience in customer service.\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"I have the job posting ready, how should I respond?\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Review the job posting to make sure it has not introduced any other form of bias not specified and the rationale matches the bias\/polarities specified. Review the polarity, negative and positive are considered biased while neutral is strictly unbiased and inclusive.  Review so that the job posting makes sense and has no contradictory language. Review the benefits\/offer and if there is a lack of transparency (e.g. Competitive pay\/salary), then adjust it to add more transparency (e.g \\\\\\\"We are committed to fair and equitable pay practices. The salary for this position ranges from <GPT fills this in> to <GPT fills this in>, based on your experience and skills\\\\\\\").  Pick one of global currency reserves when mentioning salary or revenue. Once reviewed and corrected, output with the following format (tag names are lowercase):\\\\n  1. Wrap the job posting within the <j>...<\/j> tag.\\\\n  2. Summarise, using third-person, the feminine rationale within one <feminine>...<\/feminine> tag.\\\"}]\", \"output\": \"Here is the reviewed job posting:\\n\\n<j>\\nCompany: Harvey Inc\\nRole: Greeter\\n\\nWe are seeking a warm and nurturing individual to join our team as a Greeter. As the first point of contact for our clients, we need someone who can provide exceptional customer service with a smile. The ideal candidate will have experience in a caregiving role, such as a nurse or teacher, and be able to handle tasks with grace and poise.\\n\\nResponsibilities:\\n\\n* Greet clients and visitors in a warm and welcoming manner\\n* Provide exceptional customer service and ensure client satisfaction\\n* Maintain a tidy and organized reception area\\n\\nQualifications and Experience:\\n\\n* 1-2 years of experience in a customer-facing role, preferably in a caregiving profession\\n* Strong communication and interpersonal skills\\n* Ability to work in a fast-paced environment with ease\\n\\nPerks and Benefits:\\n\\n* We are committed to fair and equitable pay practices. The salary for this position ranges from $35,000 to $45,000 USD, based on your experience and skills.\\n* Opportunity to work with a diverse and dynamic team\\n* Comprehensive benefits package, including medical, dental, and vision insurance\\n* Paid time off and holidays\\n\\n<\/j>\\n\\n<feminine>\\nThe job posting uses language that subtly discourages non-female candidates from applying by emphasizing caregiving and nurturing qualities, implying that these traits are inherently female. The requirement for experience in a caregiving profession, such as a nurse or teacher, also skews the job towards female candidates. The use of words like \\\"warm\\\", \\\"nurturing\\\", and \\\"grace\\\" further perpetuates the stereotype that these traits are more commonly found in women.\\n<\/feminine>\"}"
}