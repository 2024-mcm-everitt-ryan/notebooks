{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c6a5f862663af8b",
   "metadata": {},
   "source": [
    "Adapted from the following, but changed to handle multi-label\n",
    "https://github.com/VanekPetr/flan-t5-text-classifier/blob/main/classifier/AutoModelForSeq2SeqLM/flan-t5-finetuning.py"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Login to Hugging Face",
   "id": "fe78b8b3ad0b097a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install -q transformers datasets sentencepiece accelerate evaluate peft bitsandbytes protobuf scikit-learn\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "login(token=os.getenv(\"HF_TOKEN\"))\n",
    "\n",
    "#from huggingface_hub import notebook_login\n",
    "#notebook_login()\n",
    "# Setup"
   ],
   "id": "3d918dba9ec9b61a"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d12b7ee6dc5dc0ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:11:41.985259Z",
     "start_time": "2024-07-04T15:11:41.982765Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "base_model_id = 'google/flan-t5-base'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcebcc367d1edf29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:11:42.250697Z",
     "start_time": "2024-07-04T15:11:42.247833Z"
    }
   },
   "source": [
    "\n",
    "seed=2024\n",
    "\n",
    "# Training\n",
    "num_train_epochs=4\n",
    "batch_size = 8\n",
    "\n",
    "#learning_rate = 5e-5\n",
    "learning_rate=3e-4\n",
    "#learning_rate = 1e-3\n",
    "\n",
    "# Regularisation\n",
    "dropout_rate = 0.1\n",
    "#weight_decay=0.0001\n",
    "\n",
    "# Evaluation\n",
    "label_threshold=0.5\n",
    "\n",
    "# Misc\n",
    "results_output_dir = 'results'\n",
    "logging_dir='logs'\n",
    "\n",
    "\n",
    "\n",
    "hf_site_id = '2024-mcm-everitt-ryan'\n",
    "dataset_id = f'{hf_site_id}/job-bias-synthetic-human-benchmark'\n",
    "#dataset_id = f'{hf_site_id}/job-bias-synthetic-human-verified'\n",
    "base_model_name = base_model_id.split('/')[-1]\n",
    "model_id = f'{base_model_name}-job-bias-seq2seq-cls'\n",
    "hub_model_id = f'{hf_site_id}/{model_id}'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9c27564-3917-477d-a69f-09fdeed244c1",
   "metadata": {},
   "source": [
    "!pip install -q transformers datasets sentencepiece accelerate evaluate hf_transfer huggingface_hub scikit-learn protobuf nltk"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "bc121d59bab23a36",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddb7a63b9d9fcb8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:11:45.392134Z",
     "start_time": "2024-07-04T15:11:42.875906Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(dataset_id)\n",
    "column_names = dataset['train'].column_names\n",
    "\n",
    "\n",
    "text_col = 'text'\n",
    "label_cols = [col for col in column_names if col.startswith('label_')]\n",
    "\n",
    "labels = [label.replace(\"label_\", \"\") for label in label_cols]\n",
    "\n",
    "id2label = {idx: label for idx, label in enumerate(labels)}\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# Remove all columns apart from the two needed for multi-class classification\n",
    "keep_columns = ['id', text_col] + label_cols\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    dataset[split] = dataset[split].remove_columns(\n",
    "        [col for col in dataset[split].column_names if col not in keep_columns])\n",
    "\n",
    "for type in ['train','val','test']:\n",
    "    dataset[type] = dataset[type].shuffle(seed=seed)#.select(range(10))\n",
    "\n",
    "dataset"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tokeniser",
   "id": "8f86fe66f2538e41"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df1730b90a1dcc7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:11:45.673064Z",
     "start_time": "2024-07-04T15:11:45.392837Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, token=HfFolder.get_token())\n",
    "tokenizer"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54abe108f979a066",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:11:45.881914Z",
     "start_time": "2024-07-04T15:11:45.674144Z"
    }
   },
   "source": [
    "from datasets import concatenate_datasets\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "\n",
    "tokenized_inputs = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(\n",
    "    lambda x: tokenizer(x[\"text\"], truncation=True),\n",
    "    batched=True,\n",
    "    remove_columns=dataset['train'].column_names,\n",
    ")\n",
    "max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n",
    "print(f\"Max source length: {max_source_length}\")\n",
    "\n",
    "# Prepare target sequences for T5\n",
    "def create_target_sequence(example):\n",
    "    labels = [key.replace('label_','') for key, value in example.items() if key.startswith('label_') and value]\n",
    "    labels = ','.join(labels)\n",
    "    labels = labels.strip()    \n",
    "    return labels\n",
    "\n",
    "# Add target sequence to the dataset\n",
    "dataset = dataset.map(lambda x: {'labels': create_target_sequence(x)}, remove_columns=[col for col in dataset['train'].column_names if col.startswith('label_')])\n",
    "\n",
    "# Tokenise targets\n",
    "tokenized_targets = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(\n",
    "    lambda x: tokenizer(x[\"labels\"], truncation=True),\n",
    "    batched=True,\n",
    "    remove_columns=dataset['train'].column_names,\n",
    ")\n",
    "max_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]])\n",
    "print(f\"Max target length: {max_target_length}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2917c7f3b405da7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:11:45.898871Z",
     "start_time": "2024-07-04T15:11:45.883027Z"
    }
   },
   "source": [
    "#tokenized_targets[\"input_ids\"]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "98424c47a6f9843b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "102c5e2fda51da82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:11:49.143601Z",
     "start_time": "2024-07-04T15:11:45.899677Z"
    }
   },
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(base_model_id, dropout_rate=dropout_rate)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    config=config\n",
    ")\n",
    "model"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b1c50728f2cbab5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:11:49.147675Z",
     "start_time": "2024-07-04T15:11:49.144496Z"
    }
   },
   "source": [
    "model.config"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "98d8c8d87d17cd44",
   "metadata": {},
   "source": [
    "# Preprocessing/Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:11:53.275124Z",
     "start_time": "2024-07-04T15:11:49.148479Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, \\\n",
    "    classification_report\n",
    "import nltk\n",
    "from transformers import  DataCollatorForSeq2Seq, Seq2SeqTrainer\n",
    "import numpy as np\n",
    "from nltk import sent_tokenize\n",
    "from typing import List, Tuple\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "def preprocess_function(sample: Dataset, padding: str = \"max_length\") -> dict:\n",
    "    \"\"\"Preprocess the dataset.\"\"\"\n",
    "    inputs = [item for item in sample[\"text\"]]\n",
    "    labels = [item for item in sample[\"labels\"]]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, max_length=max_source_length, padding=padding, truncation=True\n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        text_target=labels, max_length=max_target_length, padding=padding, truncation=True\n",
    "    )\n",
    "\n",
    "    if padding == \"max_length\":\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(la if la != tokenizer.pad_token_id else -100) for la in label]\n",
    "            for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "def postprocess_text(labels: List[str], preds: List[str]) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"Helper function to postprocess text\"\"\"\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n",
    "    return labels, preds\n",
    "\n",
    "\n",
    "def compute_metrics(eval_predictions):\n",
    "    \n",
    "    y_hat, y = eval_predictions\n",
    "    \n",
    "    # Replace -100 in the labels .\n",
    "    y = np.where(y != -100, y, tokenizer.pad_token_id)\n",
    "    \n",
    "    if isinstance(y_hat, tuple):\n",
    "        y_hat = y_hat[0]\n",
    "        \n",
    "    #print(y)\n",
    "    #print('--------------------')\n",
    "    #print(y_hat)\n",
    "    \n",
    "    y_str = tokenizer.batch_decode(y, skip_special_tokens=True)\n",
    "    y_hat_str = tokenizer.batch_decode(y_hat, skip_special_tokens=True)\n",
    "\n",
    "    y_str, y_hat_str = postprocess_text( y_str, y_hat_str)\n",
    "    \n",
    "    #print('--------------------')\n",
    "    #print(y_str)\n",
    "    #print('--------------------')\n",
    "    #print(y_hat_str)\n",
    "    #print('--------------------')\n",
    "\n",
    "\n",
    "    # Flatten the list of labels\n",
    "    true_flat = [label.strip() for sublist in [t.split(',') for t in y_str] for label in sublist]\n",
    "    pred_flat = [label.strip() for sublist in [p.split(',') for p in y_hat_str] for label in sublist]\n",
    "    \n",
    "    \n",
    "    #print(true_flat)\n",
    "    #print('--------------------')\n",
    "    #print(pred_flat)\n",
    "\n",
    "    # Convert to binary format for multi-label metrics\n",
    "    #unique_labels = list(set(true_flat + pred_flat))  # This will include out-of-scope (not a label) predictions\n",
    "    unique_labels = list(set(true_flat))\n",
    "    \n",
    "    # Remove the blank label (no bias)\n",
    "    unique_labels = [label for label in unique_labels if label != '' and label is not None]\n",
    "    \n",
    "    y_true = [[1 if label in t else 0 for label in unique_labels] for t in y_str]\n",
    "    y_pred = [[1 if label in p else 0 for label in unique_labels] for p in y_hat_str]\n",
    "\n",
    "    #unique_labels = ['no_bias' if not label else label for label in unique_labels]\n",
    "\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "\n",
    "    f1_micro = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "    f1_samples = f1_score(y_true=y_true, y_pred=y_pred, average='samples')\n",
    "    f1_weighted = f1_score(y_true=y_true, y_pred=y_pred, average='weighted')\n",
    "\n",
    "    precision_micro = precision_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    recall_micro = recall_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc_micro = roc_auc_score(y_true=y_true, y_score=y_pred, average='micro')\n",
    "    \n",
    "    print(classification_report(y_true, y_pred, target_names=unique_labels))#, target_names=list(id2label.values())))\n",
    "\n",
    "    \n",
    "    #for i in range(len(y_true_str)):\n",
    "    #    yt  = [num for num in y_true_str[i] if num != 0]\n",
    "    #    yth  = [num for num in y_pred_str[i] if num != 0]\n",
    "    #    print(f't: {yt}')\n",
    "    #    print(f'p: {yth}')\n",
    "    #    print('-----------------')\n",
    "    #    print(y_true[i])\n",
    "    #    print(y_pred[i])\n",
    "    #    print('----------------------')\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        f'f1_micro': f1_micro,\n",
    "        f'f1_macro': f1_macro,\n",
    "        f'f1_samples': f1_samples,\n",
    "        f'f1_weighted': f1_weighted,\n",
    "        f'precision_micro': precision_micro,\n",
    "        f'recall_micro': recall_micro,\n",
    "        f'roc_auc_micro': roc_auc_micro}\n",
    "    return metrics\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "24f54a078782e3d2",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62c7dcb25c557604",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:11:53.396170Z",
     "start_time": "2024-07-04T15:11:53.277260Z"
    }
   },
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    learning_rate=learning_rate,\n",
    "    output_dir=results_output_dir,\n",
    "    #logging_dir=logging_dir,  # logging & evaluation strategies\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "   # weight_decay=weight_decay\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='loss',\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,  # Overflows with fp16\n",
    "    #report_to=\"tensorboard\",\n",
    "    #push_to_hub=True,\n",
    "    #hub_strategy=\"every_save\",\n",
    "    #hub_model_id=REPOSITORY_ID,\n",
    "    #hub_token=HfFolder.get_token(),\n",
    ")\n",
    "\n",
    "encoded_dataset = dataset.map(\n",
    "    preprocess_function, batched=True, remove_columns=[\"text\", \"labels\"]\n",
    ")\n",
    "print(f\"Keys of tokenized dataset: {list(encoded_dataset['train'].features)}\")\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "label_pad_token_id = -100\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer, model=model, label_pad_token_id=label_pad_token_id, pad_to_multiple_of=8\n",
    ")\n",
    "\n",
    "#early_stop = transformers.EarlyStoppingCallback(10, 1.15)\n",
    "class PrintClassificationCallback(TrainerCallback):\n",
    "    def on_evaluate(self, args, state, control, logs=None, **kwargs):\n",
    "        print(\"----------------------------------------------------------\")\n",
    "\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "594875a2793a8f29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:14:59.544387Z",
     "start_time": "2024-07-04T15:11:53.396932Z"
    }
   },
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"val\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[PrintClassificationCallback]\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # Silence the warnings.\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "trainer.train()"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate",
   "id": "1b764b5923cd4155"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bddaea63cf3ddc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:15:26.535731Z",
     "start_time": "2024-07-04T15:14:59.545113Z"
    }
   },
   "source": [
    "test_results = trainer.evaluate(eval_dataset=encoded_dataset['test'])\n",
    "test_results"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "y_true = encoded_dataset['test']['labels']\n",
    "predictions = trainer.predict(encoded_dataset['test'])\n",
    "predictions = predictions.predictions\n",
    "\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(torch.Tensor(predictions))\n",
    "# use threshold to turn them into integer predictions\n",
    "y_pred = np.zeros(probs.shape)\n",
    "y_pred[np.where(probs >= label_threshold)] = 1\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=list(id2label.values()))\n",
    "#print(report)\n",
    "\n",
    "# Convert to Markdown\n",
    "report_lines = report.split('\\n')\n",
    "markdown_classification_report = \"\\n\".join([f\"    {line}\" for line in report_lines])\n",
    "print(markdown_classification_report)"
   ],
   "id": "d8af8162d91b7d46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(list(test_results.items()), columns=['Metric', 'Value'])\n",
    "print(df.to_string(index=False))\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(list(test_results.items()), columns=['Metric', 'Value'])\n",
    "print(df.to_string(index=False))"
   ],
   "id": "3d29aa2b5692bf13"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "843e92a89b8b7b4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:15:26.573002Z",
     "start_time": "2024-07-04T15:15:26.543130Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def classify_text(text, model, tokenizer, label_columns, device):\n",
    "    input_text = f\"classify: {text}\"\n",
    "    inputs = tokenizer(input_text, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "    outputs = model.generate(**inputs)\n",
    "    predicted_labels = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    predicted_labels = [label.strip() for label in predicted_labels.split(',')]\n",
    "    label_dict = {label: False for label in label_columns}\n",
    "    for label in predicted_labels:\n",
    "        if label in label_dict:\n",
    "            label_dict[label] = True\n",
    "    return label_dict"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d76dd95a6c47d93f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:15:26.594631Z",
     "start_time": "2024-07-04T15:15:26.573803Z"
    }
   },
   "source": [
    "text = \"Looking for a native English speaker\"\n",
    "\n",
    "classify_text(text, model, tokenizer, labels, device)"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Push to Hugging Face",
   "id": "d3b121d2c658404"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab570ca8f2f2497b",
   "metadata": {},
   "source": [
    "\n",
    "from huggingface_hub import ModelCard, EvalResult, ModelCardData\n",
    "import platform\n",
    "import sys\n",
    "import os\n",
    "\n",
    "model.push_to_hub(repo_id=hub_model_id, token=HfFolder.get_token())\n",
    "tokenizer.push_to_hub(repo_id=hub_model_id, token=HfFolder.get_token())\n",
    "\n",
    "###### Update Model Card ######\n",
    "\n",
    "eval_results = []\n",
    "for k, v in test_results.items():\n",
    "    eval_results.append(EvalResult(\n",
    "        task_type='multi_label_classification',\n",
    "        dataset_type='mix_human-eval_synthetic',\n",
    "        dataset_name=dataset_id,\n",
    "        metric_type=k.replace(\"eval_\", \"\", 1),\n",
    "        metric_value=v))\n",
    "\n",
    "direct_use = \"\"\"\n",
    "    ```python\n",
    "    from transformers import pipeline\n",
    "\n",
    "    pipe = pipeline(\"text-classification\", model=\"${hub_model_id}\", return_all_scores=True)\n",
    "\n",
    "    results = pipe(\"Join our dynamic and fast-paced team as a Junior Marketing Specialist. We seek a tech-savvy and energetic individual who thrives in a vibrant environment. Ideal candidates are digital natives with a fresh perspective, ready to adapt quickly to new trends. You should have recent experience in social media strategies and a strong understanding of current digital marketing tools. We're looking for someone with a youthful mindset, eager to bring innovative ideas to our young and ambitious team. If you're a recent graduate or early in your career, this opportunity is perfect for you!\")\n",
    "    print(results)\n",
    "    ```\n",
    "    >> [[\n",
    "    {'label': 'age', 'score': 0.9883460402488708}, \n",
    "    {'label': 'disability', 'score': 0.00787709467113018}, \n",
    "    {'label': 'feminine', 'score': 0.007224376779049635}, \n",
    "    {'label': 'general', 'score': 0.09967829287052155}, \n",
    "    {'label': 'masculine', 'score': 0.0035264550242573023}, \n",
    "    {'label': 'racial', 'score': 0.014618005603551865}, \n",
    "    {'label': 'sexuality', 'score': 0.005568435415625572}\n",
    "    ]]\n",
    "\n",
    "\n",
    "    Classification Report:\n",
    "    \n",
    "    ${markdown_classification_report}\n",
    "    \"\"\"\n",
    "direct_use = direct_use.replace('${hub_model_id}', hub_model_id, -1)\n",
    "direct_use = direct_use.replace('${markdown_classification_report}', markdown_classification_report, -1)\n",
    "\n",
    "card_data = ModelCardData(\n",
    "    model_id=model_id,\n",
    "    model_name=model_id,\n",
    "    model_description=\"The model is a multi-label classifier designed to detect various types of bias within job descriptions.\",\n",
    "    base_model=base_model_id,\n",
    "    language='en',\n",
    "    license='apache-2.0',\n",
    "    developers=\"Tristan Everitt and Paul Ryan\",\n",
    "    model_card_authors='See developers',\n",
    "    model_card_contact='See developers',\n",
    "    repo=\"https://gitlab.computing.dcu.ie/everitt2/2024-mcm-everitt-ryan\",\n",
    "    eval_results=eval_results,\n",
    "    compute_infrastructure=f'{platform.system()} {platform.release()} {platform.processor()}',\n",
    "    # hardware_requirements=f\"CPUs: {psutil.cpu_count()}, Memory: {psutil.virtual_memory().total} bytes\",\n",
    "    software=f'Python {platform.python_version()}',\n",
    "    hardware_type=platform.machine(),\n",
    "    hours_used='N/A',\n",
    "    cloud_provider='N/A',\n",
    "    cloud_region='N/A',\n",
    "    co2_emitted='N/A',\n",
    "    datasets=[dataset_id],\n",
    "    direct_use=direct_use\n",
    ")\n",
    "\n",
    "card = ModelCard.from_template(card_data)\n",
    "\n",
    "card.push_to_hub(repo_id=hub_model_id, token=HfFolder.get_token())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d02fe-dcce-4d56-8137-1af6a5f0dc4b",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
