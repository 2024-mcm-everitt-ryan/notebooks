{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Multi-label Classification\n",
    "\n",
    "Adds a linear layer on top of the base model, which is used to produce a tensor of shape (batch_size, num_labels), indicating the unnormalized scores for a number of labels for every example in the batch.\n",
    "\n",
    "Based on https://github.com/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Login to Hugging Face"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#!pip install -q transformers datasets sentencepiece accelerate evaluate peft bitsandbytes protobuf scikit-learn tiktoken huggingface_hub"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "login(token=os.getenv(\"HF_TOKEN\"))\n",
    "\n",
    "#from huggingface_hub import notebook_login\n",
    "#notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Base Model\n",
    "\n",
    "base_model_id = 'google-bert/bert-large-uncased'\n",
    "\n",
    "\n",
    "seed = 2024\n",
    "\n",
    "# Training\n",
    "num_train_epochs=3\n",
    "batch_size = 8\n",
    "\n",
    "use_gradient_checkpointing = False,  # Save some memory at the expense of training\n",
    "# See https://huggingface.co/docs/transformers/main/en/perf_train_gpu_one\n",
    "gradient_accumulation_steps=1\n",
    "\n",
    "\n",
    "# 5e-5, 4e-5, 3e-5, and 2e-5\n",
    "learning_rate=3e-5\n",
    "\n",
    "# Regularisation\n",
    "hidden_dropout_prob=0.1\n",
    "attention_probs_dropout_prob=0.0\n",
    "weight_decay=0.001\n",
    "\n",
    "# Evaluation\n",
    "label_threshold=0.5\n",
    "\n",
    "\n",
    "hf_site_id = '2024-mcm-everitt-ryan'\n",
    "dataset_id = f'{hf_site_id}/job-bias-synthetic-human-benchmark-v2'\n",
    "#dataset_id = f'{hf_site_id}/job-bias-synthetic-human-verified'\n",
    "base_model_name = base_model_id.split('/')[-1]\n",
    "\n",
    "model_id = f'{base_model_name}-job-bias-seq-cls'\n",
    "hub_model_id = f'{hf_site_id}/{model_id}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T17:26:10.595794Z",
     "start_time": "2024-07-01T17:26:01.240714Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "9a1aa9f2cc29473f9f8e5459d2641e76",
      "308fa6a7348140ec981a8d6c7d31f346",
      "8bc92587e35443488445e7521fbd0a13",
      "091f8220f33241f288faa0612853585f",
      "1045bb16e3694410898a73cf1b848917",
      "cb95e545fbdd4e99903bf634df694c9f",
      "5080d322a8034924b652b379c04667ed",
      "8b1899a0c4b144d7a5e6599f8afb8b65",
      "6111a73e684a47769bda7183a836ee91",
      "cd3570ddf67541d7818d97e236c54e54",
      "bbba60f793c14100934a268063f63d26"
     ]
    },
    "id": "sd1LiXGjZ420",
    "outputId": "1b5783cd-0e4e-4c92-c67c-57b9288f2381"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'label_age', 'label_disability', 'label_masculine', 'label_feminine', 'label_racial', 'label_sexuality', 'label_general', 'text'],\n",
       "        num_rows: 4820\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['id', 'label_age', 'label_disability', 'label_masculine', 'label_feminine', 'label_racial', 'label_sexuality', 'label_general', 'text'],\n",
       "        num_rows: 1051\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'label_age', 'label_disability', 'label_masculine', 'label_feminine', 'label_racial', 'label_sexuality', 'label_general', 'text'],\n",
       "        num_rows: 1053\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(dataset_id)\n",
    "column_names = dataset['train'].column_names\n",
    "\n",
    "\n",
    "text_col = 'text'\n",
    "label_cols = [col for col in column_names if col.startswith('label_')]\n",
    "\n",
    "labels = [label.replace(\"label_\", \"\") for label in label_cols]\n",
    "\n",
    "id2label = {idx: label for idx, label in enumerate(labels)}\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# Remove all columns apart from the two needed for multi-class classification\n",
    "keep_columns = ['id', text_col] + label_cols\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    dataset[split] = dataset[split].remove_columns(\n",
    "        [col for col in dataset[split].column_names if col not in keep_columns])\n",
    "\n",
    "for type in ['train','val','test']:\n",
    "    dataset[type] = dataset[type].shuffle(seed=seed)#.select(range(10))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T17:28:51.475180Z",
     "start_time": "2024-07-01T17:28:51.439449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label_age</th>\n",
       "      <th>label_disability</th>\n",
       "      <th>label_masculine</th>\n",
       "      <th>label_feminine</th>\n",
       "      <th>label_racial</th>\n",
       "      <th>label_sexuality</th>\n",
       "      <th>label_general</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Synthetic:meta-llama:Meta-Llama-3-70B-Instruct...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Company: Harrington, Richardson and Collins\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Synthetic:meta-llama:Meta-Llama-3-70B-Instruct...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Part Time Checker at Allen Inc\\n\\nCompany Back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Synthetic:gpt-4o-2024-05-13:20240627151822:3e7...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Torres-Spencer is a leading firm in the transp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label_age  \\\n",
       "0  Synthetic:meta-llama:Meta-Llama-3-70B-Instruct...      False   \n",
       "1  Synthetic:meta-llama:Meta-Llama-3-70B-Instruct...      False   \n",
       "2  Synthetic:gpt-4o-2024-05-13:20240627151822:3e7...      False   \n",
       "\n",
       "   label_disability  label_masculine  label_feminine  label_racial  \\\n",
       "0             False            False           False          True   \n",
       "1             False            False           False          True   \n",
       "2             False            False           False          True   \n",
       "\n",
       "   label_sexuality  label_general  \\\n",
       "0            False          False   \n",
       "1            False          False   \n",
       "2            False          False   \n",
       "\n",
       "                                                text  \n",
       "0  Company: Harrington, Richardson and Collins\\n\\...  \n",
       "1  Part Time Checker at Allen Inc\\n\\nCompany Back...  \n",
       "2  Torres-Spencer is a leading firm in the transp...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Merge train,val, test into one dataframe\n",
    "df = pd.concat([\n",
    "    dataset['train'].to_pandas(),\n",
    "    dataset['val'].to_pandas(),\n",
    "    dataset['test'].to_pandas()])\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tokeniser"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T17:29:03.777886Z",
     "start_time": "2024-07-01T17:29:03.770686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n    <meta charset=\"UTF-8\">\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\\n    <title>Job Posting</title>\\n</head>\\n<body>\\n\\n<h1>Software Developer - CodeWave Solutions - Canada</h1>\\n\\n<p><strong>Company Background:</strong></p>\\n<p>CodeWave Solutions is a leading software development firm based in Toronto, Canada. We specialize in delivering innovative software solutions to clients across various industries. Our commitment to excellence and passion for technology drives us to create cutting-edge applications that power businesses worldwide.</p>\\n\\n<p><strong>Job Type:</strong> Full-time</p>\\n\\n<p><strong>Job Description:</strong></p>\\n<p>As a Software Developer at CodeWave Solutions, you will play a key role in designing, developing, and deploying high-quality software solutions. We are seeking knowledgeable candidates who are enthusiastic about technology and have a strong commitment to producing top-notch work.</p>\\n\\n<p><strong>Responsibilities:</strong></p>\\n<ul>\\n    <li>Design, develop, and maintain software applications.</li>\\n    <li>Collaborate with cross-functional teams to define project requirements and deliverables.</li>\\n    <li>Write clean, scalable, and efficient code.</li>\\n    <li>Participate in code reviews and provide constructive feedback.</li>\\n    <li>Troubleshoot, debug, and upgrade existing systems.</li>\\n    <li>Stay current with emerging technologies and industry trends.</li>\\n    <li>Develop technical documentation to support software development.</li>\\n</ul>\\n\\n<p><strong>Qualifications and Experience:</strong></p>\\n<ul>\\n    <li>Bachelor\\'s degree in Computer Science or a related field, or equivalent experience.</li>\\n    <li>3+ years of experience in software development.</li>\\n    <li>Proficiency in programming languages such as Java, Python, or C#.</li>\\n    <li>Experience with web development frameworks such as React, Angular, or Vue.js.</li>\\n    <li>Strong understanding of database management systems (SQL, NoSQL).</li>\\n    <li>Ability to work in a fast-paced and dynamic environment.</li>\\n    <li>Excellent problem-solving skills and attention to detail.</li>\\n    <li>Effective communication and teamwork skills.</li>\\n</ul>\\n\\n<p><strong>Perks and Benefits:</strong></p>\\n<ul>\\n    <li>We are committed to fair and equitable pay practices. The salary for this position ranges from CAD 80,000 to CAD 110,000, based on your experience and skills.</li>\\n    <li>Comprehensive health, dental, and vision insurance plans.</li>\\n    <li>Generous paid time off and holiday benefits.</li>\\n    <li>Opportunities for professional development and career growth.</li>\\n    <li>Flexible working arrangements, including remote work options.</li>\\n    <li>Inclusive and diverse workplace culture.</li>\\n    <li>Employee wellness programs and resources.</li>\\n    <li>Reserved parking available for employees.</li>\\n</ul>\\n\\n<p>CodeWave Solutions is dedicated to promoting diversity, equity, and inclusion. We welcome candidates from all backgrounds to join our team. Our hiring process supports diverse needs, and we strive to create a workplace that accommodates all individuals.</p>\\n\\n<p>If you are a capable candidate who is passionate about software development and eager to contribute to our dynamic team, we encourage you to apply. All eligible candidates, regardless of age, disability, gender, race, or sexual orientation, are invited to submit their applications.</p>\\n\\n<p><strong>How to Apply:</strong></p>\\n<p>To apply for the Software Developer position at CodeWave Solutions, please submit your resume and a cover letter detailing your qualifications and experience to <a href=\"mailto:careers@codewavesolutions.ca\">careers@codewavesolutions.ca</a>.</p>\\n\\n<p>We look forward to reviewing your application and exploring how you can contribute to our team!</p>\\n\\n</body>\\n</html>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Longest phrase\n",
    "longest_text = df[text_col].apply(lambda x: (len(x), x)).max()[1]\n",
    "longest_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T17:30:00.135205Z",
     "start_time": "2024-07-01T17:29:59.993343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_prefix_space=True)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T17:30:06.795705Z",
     "start_time": "2024-07-01T17:30:06.789790Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (984 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max characters: 3863\n",
      "Max words: 441\n",
      "Max tokens: 984\n"
     ]
    }
   ],
   "source": [
    "max_char = len(longest_text)\n",
    "max_words = len(longest_text.split())\n",
    "max_tokens = len(tokenizer.encode(longest_text))\n",
    "\n",
    "print(f'Max characters: {max_char}')\n",
    "print(f'Max words: {max_words}')\n",
    "print(f'Max tokens: {max_tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T17:30:15.745305Z",
     "start_time": "2024-07-01T17:30:15.742461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_max_length = min(max_tokens, tokenizer.model_max_length)\n",
    "tokenizer_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T17:30:18.135860Z",
     "start_time": "2024-07-01T17:30:18.132132Z"
    },
    "id": "AFWlSsbZaRLc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def preprocess_data(sample):\n",
    "    # take a batch of texts\n",
    "    text = sample[text_col]\n",
    "    # encode them\n",
    "    encoding = tokenizer(text, truncation=True, max_length=tokenizer_max_length, padding=\"max_length\")\n",
    "    #encoding = tokenizer(text, truncation=True, max_length=tokenizer_max_length, padding=True)\n",
    "    # add labels\n",
    "    labels_batch = {k: sample[k] for k in sample.keys() if k in label_cols}\n",
    "    # create numpy array of shape (batch_size, num_labels)\n",
    "    labels_matrix = np.zeros((len(text), len(label_cols)))\n",
    "    # fill numpy array\n",
    "    for idx, label in enumerate(label_cols):\n",
    "        labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "    encoding[\"labels\"] = labels_matrix.tolist()\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T17:30:24.593885Z",
     "start_time": "2024-07-01T17:30:22.070052Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4ENBTdulBEI",
    "outputId": "02554a1f-4961-461a-bf29-555b8debeabf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06902fc7ca434d408d8c744c544149e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1053 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ds_train = ds_train.map(tokenize, batched=True, batch_size=len(ds_train))\n",
    "encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)\n",
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5qSmCgWefWs"
   },
   "source": [
    "# Model\n",
    "\n",
    "Here we define a model that includes a pre-trained base (i.e. the weights) are loaded, with a random initialized classification head (linear layer) on top. One should fine-tune this head, together with the pre-trained base on a labeled dataset.\n",
    "\n",
    "This is also printed by the warning.\n",
    "\n",
    "We set the `problem_type` to be \"multi_label_classification\", as this will make sure the appropriate loss function is used (namely [`BCEWithLogitsLoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)). We also make sure the output layer has `len(label_cols)` output neurons, and we set the id2label and label2id mappings."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(base_model_id,\n",
    "                                                           problem_type=\"multi_label_classification\",\n",
    "                                                           num_labels=len(label_cols),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id,\n",
    "                                                           hidden_dropout_prob=hidden_dropout_prob,\n",
    "                                                          # attention_probs_dropout_prob=attention_probs_dropout_prob\n",
    "                                                          )\n",
    "\n",
    "\n",
    "model.config.use_cache = False  # Silence the warnings.\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T10:21:17.142273Z",
     "start_time": "2024-05-24T10:21:17.138307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.2,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"age\",\n",
       "    \"1\": \"disability\",\n",
       "    \"2\": \"masculine\",\n",
       "    \"3\": \"feminine\",\n",
       "    \"4\": \"racial\",\n",
       "    \"5\": \"sexuality\",\n",
       "    \"6\": \"general\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"age\": 0,\n",
       "    \"disability\": 1,\n",
       "    \"feminine\": 3,\n",
       "    \"general\": 6,\n",
       "    \"masculine\": 2,\n",
       "    \"racial\": 4,\n",
       "    \"sexuality\": 5\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"problem_type\": \"multi_label_classification\",\n",
       "  \"transformers_version\": \"4.42.3\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T10:21:18.065316Z",
     "start_time": "2024-05-24T10:21:17.752526Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, accuracy_score, classification_report\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "\n",
    "\n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "# added extras\n",
    "def multi_label_metrics(predictions, labels):\n",
    "    # apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= label_threshold)] = 1\n",
    "    y_true = labels\n",
    "\n",
    "    #print(labels)\n",
    "    #print(predictions)\n",
    "\n",
    "    print(classification_report(y_true, y_pred, target_names=list(id2label.values())))\n",
    "    \n",
    "    # return as dictionary\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    }\n",
    "    \n",
    "    for average in ['micro','macro','samples','weighted']:\n",
    "        metrics[f'f1_{average}'] = f1_score(y_true=y_true, y_pred=y_pred, average=average)\n",
    "        metrics[f'precision_{average}'] = precision_score(y_true=y_true, y_pred=y_pred, average=average)\n",
    "        metrics[f'recall_{average}'] = recall_score(y_true=y_true, y_pred=y_pred, average=average)\n",
    "        metrics[f'roc_auc_{average}'] = roc_auc_score(y_true=y_true, y_score=y_pred, average=average)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds,\n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-X2brZcv0X6"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "metric_name = \"loss\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    model_id,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1, #to prevent running out of disk space\n",
    "    learning_rate=learning_rate,\n",
    "    #optim=optimiser,\n",
    "    #lr_scheduler_type=\"cosine\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    weight_decay=weight_decay,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    fp16=False,\n",
    "    gradient_checkpointing=use_gradient_checkpointing,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    overwrite_output_dir=True,\n",
    "    group_by_length=True,\n",
    "    #push_to_hub=True,\n",
    "    #output_dir=repository_id,\n",
    "    #logging_dir=f\"{model_id}/logs\",\n",
    "    #logging_strategy=\"steps\",\n",
    "    #logging_steps=10,\n",
    "    #warmup_steps=500,\n",
    "    #warmup_ratio=0.1,\n",
    "    #max_grad_norm=0.3,\n",
    "    #save_total_limit=2,\n",
    "    #report_to=\"tensorboard\",\n",
    "    #push_to_hub=True,\n",
    "    #hub_strategy=\"every_save\",\n",
    "    #hub_model_id=hub_model_id,\n",
    "    #hub_token=HfFolder.get_token(),\n",
    ")\n",
    "\n",
    "#early_stop = transformers.EarlyStoppingCallback(10, 1.15)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"val\"],\n",
    "    # For padding a batch of examples to the maximum length seen in the batch\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    "    #tokenizer=tokenizer,\n",
    "    #   callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!nvidia-smi"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         age       0.62      0.72      0.66        81\n",
      "  disability       0.52      0.72      0.60        81\n",
      "   masculine       0.75      0.44      0.56        81\n",
      "    feminine       0.79      0.88      0.83        81\n",
      "      racial       0.53      0.88      0.67        78\n",
      "   sexuality       0.72      0.79      0.75        81\n",
      "     general       0.21      0.51      0.30        82\n",
      "\n",
      "   micro avg       0.53      0.70      0.60       565\n",
      "   macro avg       0.59      0.71      0.62       565\n",
      "weighted avg       0.59      0.70      0.62       565\n",
      " samples avg       0.33      0.36      0.33       565\n",
      "\n",
      "----------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.20577850937843323,\n",
       " 'eval_accuracy': 0.6182336182336182,\n",
       " 'eval_f1_micro': 0.6016628873771731,\n",
       " 'eval_f1_macro': 0.6248869172020873,\n",
       " 'eval_f1_samples': 0.334156378600823,\n",
       " 'eval_f1_weighted': 0.6240938766848936,\n",
       " 'eval_precision_micro': 0.525065963060686,\n",
       " 'eval_recall_micro': 0.7044247787610619,\n",
       " 'eval_roc_auc_micro': 0.8257651369561995,\n",
       " 'eval_runtime': 3.5732,\n",
       " 'eval_samples_per_second': 294.697,\n",
       " 'eval_steps_per_second': 9.236,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = trainer.evaluate(eval_dataset=encoded_dataset['test'])\n",
    "test_results"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "y_true = encoded_dataset['test']['labels']\n",
    "predictions = trainer.predict(encoded_dataset['test'])\n",
    "predictions = predictions.predictions\n",
    "\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(torch.Tensor(predictions))\n",
    "# use threshold to turn them into integer predictions\n",
    "y_pred = np.zeros(probs.shape)\n",
    "y_pred[np.where(probs >= label_threshold)] = 1\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=list(id2label.values()))\n",
    "#print(report)\n",
    "\n",
    "# Convert to Markdown\n",
    "report_lines = report.split('\\n')\n",
    "markdown_classification_report = \"\\n\".join([f\"    {line}\" for line in report_lines])\n",
    "print(markdown_classification_report)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(list(test_results.items()), columns=['Metric', 'Value'])\n",
    "print(df.to_string(index=False))\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(list(test_results.items()), columns=['Metric', 'Value'])\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push to Hugging Face"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "from huggingface_hub import ModelCard, EvalResult, ModelCardData\n",
    "import platform\n",
    "import sys\n",
    "import os\n",
    "\n",
    "model.push_to_hub(repo_id=hub_model_id, token=HfFolder.get_token())\n",
    "tokenizer.push_to_hub(repo_id=hub_model_id, token=HfFolder.get_token())"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "args.to_sanitized_dict()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from huggingface_hub import ModelCard, EvalResult, ModelCardData\n",
    "import platform\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "training_regime = []\n",
    "training_regime_args = args.to_sanitized_dict()\n",
    "for k,v in training_regime_args.items():\n",
    "    if (isinstance(v, (int, str, bool, float))\n",
    "            and '_dir' not in k\n",
    "            and 'logging' not in k\n",
    "            and 'log_' not in k\n",
    "            and 'hub_' not in k\n",
    "            and '_hub' not in k\n",
    "            and 'save_' not in k\n",
    "            and 'run_name' not in k\n",
    "            and 'debug' not in k\n",
    "            and 'token' not in k):\n",
    "        training_regime.append(f'{k}={json.dumps(v)}')\n",
    "\n",
    "training_regime = sorted(training_regime)\n",
    "\n",
    "training_regime = ', '.join(training_regime)\n",
    "\n",
    "\n",
    "## Hardware\n",
    "compute_infrastructure = []\n",
    "mem_total = !cat /proc/meminfo | grep MemTotal\n",
    "mem_total = list(set(mem_total))[0]\n",
    "cpu_info = !cat /proc/cpuinfo | grep \"model name\"\n",
    "cpu_count = len(list(cpu_info))\n",
    "cpu_name = list(set(cpu_info))[0]\n",
    "cpu_name = cpu_name.strip()\n",
    "cpu_name = cpu_name.replace('model name\\t:', '')\n",
    "cpu_name = cpu_name.strip()\n",
    "\n",
    "compute_infrastructure.append(f'- {platform.system()} {platform.release()} {platform.processor()}')\n",
    "compute_infrastructure.append(f'- {mem_total}')\n",
    "compute_infrastructure.append(f'- {cpu_count} X {cpu_name}')\n",
    "\n",
    "\n",
    "gpu_name = !nvidia-smi --query-gpu=gpu_name --format=csv,noheader\n",
    "gpus = set()\n",
    "for idx, gpu in enumerate(gpu_name):\n",
    "    compute_infrastructure.append(f\"- GPU_{idx}: {gpu}\")\n",
    "    gpus.add(gpu)\n",
    "\n",
    "gpus =list(gpus)\n",
    "compute_infrastructure = '\\n'.join(compute_infrastructure)\n",
    "hardware_type = f'{len(gpus)} X {gpus[0]}'\n",
    "\n",
    "## Software\n",
    "software_list = !pip list\n",
    "inc_software = []\n",
    "inc_software.append(f'python {platform.python_version()}')\n",
    "\n",
    "for software in software_list:\n",
    "    if software and '[notice]' not in software and '---' not in software and 'Package' not in software:\n",
    "        inc_software.append(' '.join(software.split()))\n",
    " \n",
    "\n",
    "software = \", \".join(inc_software)   \n",
    "\n",
    "hours_used = \"\"\n",
    "eval_results = []\n",
    "for k, v in test_results.items():\n",
    "    metric_type = k.replace(\"eval_\", \"\", 1)\n",
    "    if metric_type == 'runtime':\n",
    "        hours_used = f\"{int(v)/60.0:.2f}\"\n",
    "    eval_results.append(EvalResult(\n",
    "        task_type='multi_label_classification',\n",
    "        dataset_type='mix_human-eval_synthetic',\n",
    "        dataset_name=dataset_id,\n",
    "        metric_type=metric_type,\n",
    "        metric_value=v))\n",
    "\n",
    "direct_use = \"\"\"\n",
    "    ```python\n",
    "    from transformers import pipeline\n",
    "\n",
    "    pipe = pipeline(\"text-classification\", model=\"${hub_model_id}\", return_all_scores=True)\n",
    "\n",
    "    results = pipe(\"Join our dynamic and fast-paced team as a Junior Marketing Specialist. We seek a tech-savvy and energetic individual who thrives in a vibrant environment. Ideal candidates are digital natives with a fresh perspective, ready to adapt quickly to new trends. You should have recent experience in social media strategies and a strong understanding of current digital marketing tools. We're looking for someone with a youthful mindset, eager to bring innovative ideas to our young and ambitious team. If you're a recent graduate or early in your career, this opportunity is perfect for you!\")\n",
    "    print(results)\n",
    "    ```\n",
    "    >> [[\n",
    "    {'label': 'age', 'score': 0.9883460402488708}, \n",
    "    {'label': 'disability', 'score': 0.00787709467113018}, \n",
    "    {'label': 'feminine', 'score': 0.007224376779049635}, \n",
    "    {'label': 'general', 'score': 0.09967829287052155}, \n",
    "    {'label': 'masculine', 'score': 0.0035264550242573023}, \n",
    "    {'label': 'racial', 'score': 0.014618005603551865}, \n",
    "    {'label': 'sexuality', 'score': 0.005568435415625572}\n",
    "    ]]\n",
    "    \"\"\"\n",
    "\n",
    "direct_use = direct_use.replace('${hub_model_id}', hub_model_id, -1)\n",
    "\n",
    "card_data = ModelCardData(\n",
    "    model_id=model_id,\n",
    "    model_name=model_id,\n",
    "    model_description=\"The model is a multi-label classifier designed to detect various types of bias within job descriptions.\",\n",
    "    base_model=base_model_id,\n",
    "    language='en',\n",
    "    license='apache-2.0',\n",
    "    developers=\"Tristan Everitt and Paul Ryan\",\n",
    "    model_card_authors='See developers',\n",
    "    model_card_contact='See developers',\n",
    "    repo=\"https://gitlab.computing.dcu.ie/everitt2/2024-mcm-everitt-ryan\",\n",
    "    training_regime=training_regime,\n",
    "    eval_results=eval_results,\n",
    "    results=markdown_classification_report,\n",
    "    compute_infrastructure=compute_infrastructure,\n",
    "    # hardware_requirements='N/A',\n",
    "    software=software,\n",
    "    hardware_type=hardware_type,\n",
    "    hours_used=hours_used,\n",
    "    cloud_provider='N/A',\n",
    "    cloud_region='N/A',\n",
    "    co2_emitted='N/A',\n",
    "    datasets=[dataset_id],\n",
    "    direct_use=direct_use\n",
    ")\n",
    "\n",
    "card = ModelCard.from_template(card_data)\n",
    "\n",
    "card.push_to_hub(repo_id=hub_model_id, token=HfFolder.get_token())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMiblo1Ci0GTlAbbA5wB3mn",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Fine-tuning BERT (and friends) for multi-label text classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "091f8220f33241f288faa0612853585f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6111a73e684a47769bda7183a836ee91",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8b1899a0c4b144d7a5e6599f8afb8b65",
      "value": 3
     }
    },
    "1045bb16e3694410898a73cf1b848917": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbba60f793c14100934a268063f63d26",
      "placeholder": "​",
      "style": "IPY_MODEL_cd3570ddf67541d7818d97e236c54e54",
      "value": " 3/3 [00:00&lt;00:00, 75.93it/s]"
     }
    },
    "308fa6a7348140ec981a8d6c7d31f346": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5080d322a8034924b652b379c04667ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6111a73e684a47769bda7183a836ee91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b1899a0c4b144d7a5e6599f8afb8b65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8bc92587e35443488445e7521fbd0a13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5080d322a8034924b652b379c04667ed",
      "placeholder": "​",
      "style": "IPY_MODEL_cb95e545fbdd4e99903bf634df694c9f",
      "value": "100%"
     }
    },
    "9a1aa9f2cc29473f9f8e5459d2641e76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8bc92587e35443488445e7521fbd0a13",
       "IPY_MODEL_091f8220f33241f288faa0612853585f",
       "IPY_MODEL_1045bb16e3694410898a73cf1b848917"
      ],
      "layout": "IPY_MODEL_308fa6a7348140ec981a8d6c7d31f346"
     }
    },
    "bbba60f793c14100934a268063f63d26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb95e545fbdd4e99903bf634df694c9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd3570ddf67541d7818d97e236c54e54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
