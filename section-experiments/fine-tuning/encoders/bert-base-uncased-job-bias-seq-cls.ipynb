{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Multi-label Classification\n",
    "\n",
    "Adds a linear layer on top of the base model, which is used to produce a tensor of shape (batch_size, num_labels), indicating the unnormalized scores for a number of labels for every example in the batch.\n",
    "\n",
    "Based on https://github.com/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Login to Hugging Face"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T20:20:30.785850Z",
     "start_time": "2024-07-16T20:20:28.089402Z"
    }
   },
   "cell_type": "code",
   "source": "#!pip install -q transformers datasets sentencepiece accelerate evaluate peft bitsandbytes protobuf scikit-learn tiktoken huggingface_hub",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.3.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.1.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T20:20:30.882164Z",
     "start_time": "2024-07-16T20:20:30.787229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "login(token=os.getenv(\"HF_TOKEN\"))\n",
    "\n",
    "#from huggingface_hub import notebook_login\n",
    "#notebook_login()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9d7625b40f0474793762eff8615670c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Base Model\n",
    "\n",
    "base_model_id = 'google-bert/bert-base-uncased'\n",
    "\n",
    "\n",
    "seed = 2024\n",
    "\n",
    "# Training\n",
    "num_train_epochs=3\n",
    "batch_size = 8\n",
    "\n",
    "use_gradient_checkpointing = False,  # Save some memory at the expense of training\n",
    "# See https://huggingface.co/docs/transformers/main/en/perf_train_gpu_one\n",
    "gradient_accumulation_steps=1\n",
    "\n",
    "\n",
    "# 5e-5, 4e-5, 3e-5, and 2e-5\n",
    "learning_rate=3e-5\n",
    "\n",
    "# Regularisation\n",
    "hidden_dropout_prob=0.1\n",
    "attention_probs_dropout_prob=0.0\n",
    "weight_decay=0.001\n",
    "\n",
    "# Evaluation\n",
    "label_threshold=0.5\n",
    "\n",
    "\n",
    "hf_site_id = '2024-mcm-everitt-ryan'\n",
    "dataset_id = f'{hf_site_id}/job-bias-synthetic-human-benchmark-v2'\n",
    "#dataset_id = f'{hf_site_id}/job-bias-synthetic-human-verified'\n",
    "base_model_name = base_model_id.split('/')[-1]\n",
    "\n",
    "model_id = f'{base_model_name}-job-bias-seq-cls'\n",
    "hub_model_id = f'{hf_site_id}/{model_id}'"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4wxY3x-ZZz8h"
   },
   "source": "",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "9a1aa9f2cc29473f9f8e5459d2641e76",
      "308fa6a7348140ec981a8d6c7d31f346",
      "8bc92587e35443488445e7521fbd0a13",
      "091f8220f33241f288faa0612853585f",
      "1045bb16e3694410898a73cf1b848917",
      "cb95e545fbdd4e99903bf634df694c9f",
      "5080d322a8034924b652b379c04667ed",
      "8b1899a0c4b144d7a5e6599f8afb8b65",
      "6111a73e684a47769bda7183a836ee91",
      "cd3570ddf67541d7818d97e236c54e54",
      "bbba60f793c14100934a268063f63d26"
     ]
    },
    "id": "sd1LiXGjZ420",
    "outputId": "1b5783cd-0e4e-4c92-c67c-57b9288f2381",
    "ExecuteTime": {
     "end_time": "2024-07-16T20:20:35.396669Z",
     "start_time": "2024-07-16T20:20:30.887857Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(dataset_id)\n",
    "column_names = dataset['train'].column_names\n",
    "\n",
    "\n",
    "text_col = 'text'\n",
    "label_cols = [col for col in column_names if col.startswith('label_')]\n",
    "\n",
    "labels = [label.replace(\"label_\", \"\") for label in label_cols]\n",
    "\n",
    "id2label = {idx: label for idx, label in enumerate(labels)}\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# Remove all columns apart from the two needed for multi-class classification\n",
    "keep_columns = ['id', text_col] + label_cols\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    dataset[split] = dataset[split].remove_columns(\n",
    "        [col for col in dataset[split].column_names if col not in keep_columns])\n",
    "\n",
    "for type in ['train','val','test']:\n",
    "    dataset[type] = dataset[type].shuffle(seed=seed)#.select(range(10))\n",
    "\n",
    "dataset"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'label_age', 'label_disability', 'label_feminine', 'label_general', 'label_masculine', 'label_neutral', 'label_racial', 'label_sexuality', 'text'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['id', 'label_age', 'label_disability', 'label_feminine', 'label_general', 'label_masculine', 'label_neutral', 'label_racial', 'label_sexuality', 'text'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'label_age', 'label_disability', 'label_feminine', 'label_general', 'label_masculine', 'label_neutral', 'label_racial', 'label_sexuality', 'text'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T20:20:35.423598Z",
     "start_time": "2024-07-16T20:20:35.397549Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Merge train,val, test into one dataframe\n",
    "df = pd.concat([\n",
    "    dataset['train'].to_pandas(),\n",
    "    dataset['val'].to_pandas(),\n",
    "    dataset['test'].to_pandas()])\n",
    "\n",
    "df.head(3)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  id  label_age  \\\n",
       "0  Synthetic:gpt-4o-2024-05-13:20240702101936:mix...      False   \n",
       "1  Synthetic:gpt-4o-2024-05-13:20240702134521:mix...       True   \n",
       "2  Synthetic:gpt-4o-2024-05-13:20240702133715:mix...      False   \n",
       "\n",
       "   label_disability  label_feminine  label_general  label_masculine  \\\n",
       "0             False           False          False            False   \n",
       "1              True           False          False            False   \n",
       "2             False           False          False             True   \n",
       "\n",
       "   label_neutral  label_racial  label_sexuality  \\\n",
       "0          False          True            False   \n",
       "1          False         False             True   \n",
       "2          False         False            False   \n",
       "\n",
       "                                                text  \n",
       "0  Company: Rotterdam Resources Solutions\\n\\nCoun...  \n",
       "1  Company Name: Inclusive Horizons Ltd.\\n\\nJob T...  \n",
       "2  Company Background:\\nEagleTech Solutions is a ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label_age</th>\n",
       "      <th>label_disability</th>\n",
       "      <th>label_feminine</th>\n",
       "      <th>label_general</th>\n",
       "      <th>label_masculine</th>\n",
       "      <th>label_neutral</th>\n",
       "      <th>label_racial</th>\n",
       "      <th>label_sexuality</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Synthetic:gpt-4o-2024-05-13:20240702101936:mix...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Company: Rotterdam Resources Solutions\\n\\nCoun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Synthetic:gpt-4o-2024-05-13:20240702134521:mix...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Company Name: Inclusive Horizons Ltd.\\n\\nJob T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Synthetic:gpt-4o-2024-05-13:20240702133715:mix...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Company Background:\\nEagleTech Solutions is a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tokeniser"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T20:20:35.427620Z",
     "start_time": "2024-07-16T20:20:35.424394Z"
    }
   },
   "source": [
    "# Longest phrase\n",
    "longest_text = df[text_col].apply(lambda x: (len(x), x)).max()[1]\n",
    "longest_text"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Be highly self-motivated, possessing strong enthusiasm and commitment to delivering sustainable outcomes. Experience of development of complex technical reports in line with regulatory environmental and sustainability requirements.\\n\\nDesirable:\\n- Experience of the management/co-ordination of EIA environmental planning in KSA.\\n- Experience of natural resource management.\\n- Practical experience in the solid waste management sector.\\n- Experience of multi-disciplinary work in large scale developments in region.\\n- Arabic speaking.\\n- Driving Licence.\\n\\nResponsibilities:\\n- Leading on the coordination and delivery of environmental work being undertaken by multi-disciplinary teams including ESIA, options appraisals, and environmental management.\\n- Championing high standards of environmental performance within multidisciplinary engineering projects, influencing project development and delivering optimal environmental outcomes.\\n- Providing technical planning advice to key clients and Atkins design teams.\\n- Developing Environmental management processes, procedures & guidelines for all projects.\\n- Co-ordinating multi-disciplinary design teams to enable the development of integrated sustainable design solutions.\\n- Establishing a network of expert resources from existing stakeholders.\\n- Managing technical and commercial aspects of bid development, project delivery and develop new areas of business for the team.\\n- Meeting with regulators and obtaining statutory approvals for environment components of projects.\\n- Collating and editing information from a range of sources to provide clear, well written reports.\\n- Competently undertake own work to an excellent standard, and review the work of others, on time and to budget.\\n- Able to manage clients needs in a confident, professional manner.\\n- Lead and support on bid preparation and develop new areas of business for the team.\\n- Undertake Continual Professional Development in accordance with requirements of chosen professional institute.\\n\\nSalary & Benefits:\\nWe offer an excellent package which includes:\\n- A competitive salary.\\n- Accommodation allowance.\\n- Transportation allowance.\\n- 22 working days annual leave.\\n- Medical and life insurance cover.\\n- Company gratuity scheme.\\n- Discretionary bonus scheme.\\n- Annual flight allowance to point of origin.\\n- Employee Assistance Programme 24 hour free advice on financial, legal and family care specialists and also access to personal health, fitness and nutrition consultants.\\n\\nWorker Type:\\n- Employee.\\n\\nJob Type:\\n- Regular.\\n\\nAt SNC-Lavalin, we seek to hire individuals with diverse characteristics, backgrounds and perspectives. We strongly believe that world-class talent makes no distinctions based on gender, ethnic or national origin, sexual identity and orientation, age, religion or disability, but enriches itself through these differences. SNC-Lavalin cares about your privacy. SNC-Lavalin and other subsidiary or affiliated companies of SNC-Lavalin (referred to throughout as SNC-Lavalin) are committed to protecting your privacy.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T20:20:36.308744Z",
     "start_time": "2024-07-16T20:20:35.428274Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_prefix_space=True)\n",
    "tokenizer"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='google-bert/bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T20:20:36.315400Z",
     "start_time": "2024-07-16T20:20:36.310113Z"
    }
   },
   "source": [
    "max_char = len(longest_text)\n",
    "max_words = len(longest_text.split())\n",
    "max_tokens = len(tokenizer.encode(longest_text))\n",
    "\n",
    "print(f'Max characters: {max_char}')\n",
    "print(f'Max words: {max_words}')\n",
    "print(f'Max tokens: {max_tokens}')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max characters: 3048\n",
      "Max words: 418\n",
      "Max tokens: 540\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T20:20:36.326400Z",
     "start_time": "2024-07-16T20:20:36.316304Z"
    }
   },
   "source": [
    "tokenizer_max_length = min(max_tokens, tokenizer.model_max_length)\n",
    "tokenizer_max_length"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AFWlSsbZaRLc",
    "ExecuteTime": {
     "end_time": "2024-07-16T20:20:36.331042Z",
     "start_time": "2024-07-16T20:20:36.327240Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def preprocess_data(sample):\n",
    "    # take a batch of texts\n",
    "    text = sample[text_col]\n",
    "    # encode them\n",
    "    encoding = tokenizer(text, truncation=True, max_length=tokenizer_max_length, padding=\"max_length\")\n",
    "    #encoding = tokenizer(text, truncation=True, max_length=tokenizer_max_length, padding=True)\n",
    "    # add labels\n",
    "    labels_batch = {k: sample[k] for k in sample.keys() if k in label_cols}\n",
    "    # create numpy array of shape (batch_size, num_labels)\n",
    "    labels_matrix = np.zeros((len(text), len(label_cols)))\n",
    "    # fill numpy array\n",
    "    for idx, label in enumerate(label_cols):\n",
    "        labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "    encoding[\"labels\"] = labels_matrix.tolist()\n",
    "\n",
    "    return encoding"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4ENBTdulBEI",
    "outputId": "02554a1f-4961-461a-bf29-555b8debeabf",
    "ExecuteTime": {
     "end_time": "2024-07-16T20:20:36.479234Z",
     "start_time": "2024-07-16T20:20:36.331822Z"
    }
   },
   "source": [
    "#ds_train = ds_train.map(tokenize, batched=True, batch_size=len(ds_train))\n",
    "encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)\n",
    "encoded_dataset.set_format(\"torch\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81ec3ed599a54311aee73afb0b8c8205"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bef45562bbef4160bd5e9613d7633769"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af800295a44142d4b6b708cdbc467899"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5qSmCgWefWs"
   },
   "source": [
    "# Model\n",
    "\n",
    "Here we define a model that includes a pre-trained base (i.e. the weights) are loaded, with a random initialized classification head (linear layer) on top. One should fine-tune this head, together with the pre-trained base on a labeled dataset.\n",
    "\n",
    "This is also printed by the warning.\n",
    "\n",
    "We set the `problem_type` to be \"multi_label_classification\", as this will make sure the appropriate loss function is used (namely [`BCEWithLogitsLoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)). We also make sure the output layer has `len(label_cols)` output neurons, and we set the id2label and label2id mappings."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XPL1Z_RegBF",
    "outputId": "22994300-8c93-421e-faa4-678d6cc14aab",
    "ExecuteTime": {
     "end_time": "2024-07-16T20:20:38.487292Z",
     "start_time": "2024-07-16T20:20:36.480289Z"
    }
   },
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(base_model_id,\n",
    "                                                           problem_type=\"multi_label_classification\",\n",
    "                                                           num_labels=len(label_cols),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id,\n",
    "                                                           hidden_dropout_prob=hidden_dropout_prob,\n",
    "                                                          # attention_probs_dropout_prob=attention_probs_dropout_prob\n",
    "                                                          )\n",
    "\n",
    "\n",
    "model.config.use_cache = False  # Silence the warnings.\n",
    "\n",
    "model"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T20:20:38.492355Z",
     "start_time": "2024-07-16T20:20:38.488744Z"
    }
   },
   "source": [
    "model.config"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"google-bert/bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"age\",\n",
       "    \"1\": \"disability\",\n",
       "    \"2\": \"feminine\",\n",
       "    \"3\": \"general\",\n",
       "    \"4\": \"masculine\",\n",
       "    \"5\": \"neutral\",\n",
       "    \"6\": \"racial\",\n",
       "    \"7\": \"sexuality\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"age\": 0,\n",
       "    \"disability\": 1,\n",
       "    \"feminine\": 2,\n",
       "    \"general\": 3,\n",
       "    \"masculine\": 4,\n",
       "    \"neutral\": 5,\n",
       "    \"racial\": 6,\n",
       "    \"sexuality\": 7\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"problem_type\": \"multi_label_classification\",\n",
       "  \"transformers_version\": \"4.39.3\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": false,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T20:20:38.737525Z",
     "start_time": "2024-07-16T20:20:38.492994Z"
    }
   },
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, accuracy_score, classification_report\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "\n",
    "\n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "# added extras\n",
    "def multi_label_metrics(predictions, labels):\n",
    "    # apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= label_threshold)] = 1\n",
    "    y_true = labels\n",
    "\n",
    "    #print(labels)\n",
    "    #print(predictions)\n",
    "\n",
    "    print(classification_report(y_true, y_pred, target_names=list(id2label.values())))\n",
    "    \n",
    "    # return as dictionary\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    }\n",
    "    \n",
    "    for average in ['micro','macro','samples','weighted']:\n",
    "        metrics[f'f1_{average}'] = f1_score(y_true=y_true, y_pred=y_pred, average=average)\n",
    "        metrics[f'precision_{average}'] = precision_score(y_true=y_true, y_pred=y_pred, average=average)\n",
    "        metrics[f'recall_{average}'] = recall_score(y_true=y_true, y_pred=y_pred, average=average)\n",
    "        metrics[f'roc_auc_{average}'] = roc_auc_score(y_true=y_true, y_score=y_pred, average=average)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds,\n",
    "        labels=p.label_ids)\n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-X2brZcv0X6"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T20:20:40.491629Z",
     "start_time": "2024-07-16T20:20:38.738297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "metric_name = \"loss\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    model_id,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1, #to prevent running out of disk space\n",
    "    learning_rate=learning_rate,\n",
    "    #optim=optimiser,\n",
    "    #lr_scheduler_type=\"cosine\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    weight_decay=weight_decay,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    fp16=False,\n",
    "    gradient_checkpointing=use_gradient_checkpointing,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    overwrite_output_dir=True,\n",
    "    group_by_length=True,\n",
    "    #push_to_hub=True,\n",
    "    #output_dir=repository_id,\n",
    "    #logging_dir=f\"{model_id}/logs\",\n",
    "    #logging_strategy=\"steps\",\n",
    "    #logging_steps=10,\n",
    "    #warmup_steps=500,\n",
    "    #warmup_ratio=0.1,\n",
    "    #max_grad_norm=0.3,\n",
    "    #save_total_limit=2,\n",
    "    #report_to=\"tensorboard\",\n",
    "    #push_to_hub=True,\n",
    "    #hub_strategy=\"every_save\",\n",
    "    #hub_model_id=hub_model_id,\n",
    "    #hub_token=HfFolder.get_token(),\n",
    ")\n",
    "\n",
    "#early_stop = transformers.EarlyStoppingCallback(10, 1.15)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"val\"],\n",
    "    # For padding a batch of examples to the maximum length seen in the batch\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    "    #tokenizer=tokenizer,\n",
    "    #   callbacks=[early_stop]\n",
    ")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 21:20:38.872108: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-16 21:20:38.908232: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T20:20:40.783794Z",
     "start_time": "2024-07-16T20:20:40.492730Z"
    }
   },
   "cell_type": "code",
   "source": "!nvidia-smi",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 16 21:20:40 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA RTX A2000 12GB          On  | 00000000:1C:00.0 Off |                  Off |\r\n",
      "| 42%   69C    P2              28W /  70W |    715MiB / 12282MiB |     17%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A      3586      G   /usr/lib/xorg/Xorg                            4MiB |\r\n",
      "|    0   N/A  N/A      4520      C   /usr/NX/bin/nxnode.bin                      131MiB |\r\n",
      "|    0   N/A  N/A    171079      C   /usr/bin/python3                            568MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T20:21:00.356130Z",
     "start_time": "2024-07-16T20:20:40.785227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "trainer.train()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:18, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>Precision Micro</th>\n",
       "      <th>Recall Micro</th>\n",
       "      <th>Roc Auc Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>Roc Auc Macro</th>\n",
       "      <th>F1 Samples</th>\n",
       "      <th>Precision Samples</th>\n",
       "      <th>Recall Samples</th>\n",
       "      <th>Roc Auc Samples</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Precision Weighted</th>\n",
       "      <th>Recall Weighted</th>\n",
       "      <th>Roc Auc Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.450814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         age       0.00      0.00      0.00        10\n",
      "  disability       0.00      0.00      0.00        12\n",
      "    feminine       0.00      0.00      0.00        17\n",
      "     general       0.00      0.00      0.00        10\n",
      "   masculine       0.00      0.00      0.00        11\n",
      "     neutral       0.00      0.00      0.00        18\n",
      "      racial       0.00      0.00      0.00        12\n",
      "   sexuality       0.00      0.00      0.00        15\n",
      "\n",
      "   micro avg       0.00      0.00      0.00       105\n",
      "   macro avg       0.00      0.00      0.00       105\n",
      "weighted avg       0.00      0.00      0.00       105\n",
      " samples avg       0.00      0.00      0.00       105\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=34, training_loss=0.5890346975887523, metrics={'train_runtime': 19.361, 'train_samples_per_second': 5.165, 'train_steps_per_second': 1.756, 'total_flos': 26312522956800.0, 'train_loss': 0.5890346975887523, 'epoch': 1.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T20:21:03.671123Z",
     "start_time": "2024-07-16T20:21:00.356896Z"
    }
   },
   "source": [
    "test_results = trainer.evaluate(eval_dataset=encoded_dataset['test'])\n",
    "test_results"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         age       0.00      0.00      0.00         9\n",
      "  disability       0.00      0.00      0.00        11\n",
      "    feminine       0.00      0.00      0.00        17\n",
      "     general       0.00      0.00      0.00        17\n",
      "   masculine       0.00      0.00      0.00        14\n",
      "     neutral       0.00      0.00      0.00        16\n",
      "      racial       0.00      0.00      0.00        12\n",
      "   sexuality       0.00      0.00      0.00        11\n",
      "\n",
      "   micro avg       0.00      0.00      0.00       107\n",
      "   macro avg       0.00      0.00      0.00       107\n",
      "weighted avg       0.00      0.00      0.00       107\n",
      " samples avg       0.00      0.00      0.00       107\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4532519578933716,\n",
       " 'eval_accuracy': 0.0,\n",
       " 'eval_f1_micro': 0.0,\n",
       " 'eval_precision_micro': 0.0,\n",
       " 'eval_recall_micro': 0.0,\n",
       " 'eval_roc_auc_micro': 0.5,\n",
       " 'eval_f1_macro': 0.0,\n",
       " 'eval_precision_macro': 0.0,\n",
       " 'eval_recall_macro': 0.0,\n",
       " 'eval_roc_auc_macro': 0.5,\n",
       " 'eval_f1_samples': 0.0,\n",
       " 'eval_precision_samples': 0.0,\n",
       " 'eval_recall_samples': 0.0,\n",
       " 'eval_roc_auc_samples': 0.5,\n",
       " 'eval_f1_weighted': 0.0,\n",
       " 'eval_precision_weighted': 0.0,\n",
       " 'eval_recall_weighted': 0.0,\n",
       " 'eval_roc_auc_weighted': 0.5,\n",
       " 'eval_runtime': 3.3062,\n",
       " 'eval_samples_per_second': 30.246,\n",
       " 'eval_steps_per_second': 10.284,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T20:21:07.003671Z",
     "start_time": "2024-07-16T20:21:03.671686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "y_true = encoded_dataset['test']['labels']\n",
    "predictions = trainer.predict(encoded_dataset['test'])\n",
    "predictions = predictions.predictions\n",
    "\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(torch.Tensor(predictions))\n",
    "# use threshold to turn them into integer predictions\n",
    "y_pred = np.zeros(probs.shape)\n",
    "y_pred[np.where(probs >= label_threshold)] = 1\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=list(id2label.values()))\n",
    "#print(report)\n",
    "\n",
    "# Convert to Markdown\n",
    "report_lines = report.split('\\n')\n",
    "markdown_classification_report = \"\\n\".join([f\"    {line}\" for line in report_lines])\n",
    "print(markdown_classification_report)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         age       0.00      0.00      0.00         9\n",
      "  disability       0.00      0.00      0.00        11\n",
      "    feminine       0.00      0.00      0.00        17\n",
      "     general       0.00      0.00      0.00        17\n",
      "   masculine       0.00      0.00      0.00        14\n",
      "     neutral       0.00      0.00      0.00        16\n",
      "      racial       0.00      0.00      0.00        12\n",
      "   sexuality       0.00      0.00      0.00        11\n",
      "\n",
      "   micro avg       0.00      0.00      0.00       107\n",
      "   macro avg       0.00      0.00      0.00       107\n",
      "weighted avg       0.00      0.00      0.00       107\n",
      " samples avg       0.00      0.00      0.00       107\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "    \n",
      "             age       0.00      0.00      0.00         9\n",
      "      disability       0.00      0.00      0.00        11\n",
      "        feminine       0.00      0.00      0.00        17\n",
      "         general       0.00      0.00      0.00        17\n",
      "       masculine       0.00      0.00      0.00        14\n",
      "         neutral       0.00      0.00      0.00        16\n",
      "          racial       0.00      0.00      0.00        12\n",
      "       sexuality       0.00      0.00      0.00        11\n",
      "    \n",
      "       micro avg       0.00      0.00      0.00       107\n",
      "       macro avg       0.00      0.00      0.00       107\n",
      "    weighted avg       0.00      0.00      0.00       107\n",
      "     samples avg       0.00      0.00      0.00       107\n",
      "    \n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T20:21:07.011179Z",
     "start_time": "2024-07-16T20:21:07.005623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(list(test_results.items()), columns=['Metric', 'Value'])\n",
    "print(df.to_string(index=False))\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(list(test_results.items()), columns=['Metric', 'Value'])\n",
    "print(df.to_string(index=False))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric     Value\n",
      "              eval_loss  0.453252\n",
      "          eval_accuracy  0.000000\n",
      "          eval_f1_micro  0.000000\n",
      "   eval_precision_micro  0.000000\n",
      "      eval_recall_micro  0.000000\n",
      "     eval_roc_auc_micro  0.500000\n",
      "          eval_f1_macro  0.000000\n",
      "   eval_precision_macro  0.000000\n",
      "      eval_recall_macro  0.000000\n",
      "     eval_roc_auc_macro  0.500000\n",
      "        eval_f1_samples  0.000000\n",
      " eval_precision_samples  0.000000\n",
      "    eval_recall_samples  0.000000\n",
      "   eval_roc_auc_samples  0.500000\n",
      "       eval_f1_weighted  0.000000\n",
      "eval_precision_weighted  0.000000\n",
      "   eval_recall_weighted  0.000000\n",
      "  eval_roc_auc_weighted  0.500000\n",
      "           eval_runtime  3.306200\n",
      "eval_samples_per_second 30.246000\n",
      "  eval_steps_per_second 10.284000\n",
      "                  epoch  1.000000\n",
      "                 Metric     Value\n",
      "              eval_loss  0.453252\n",
      "          eval_accuracy  0.000000\n",
      "          eval_f1_micro  0.000000\n",
      "   eval_precision_micro  0.000000\n",
      "      eval_recall_micro  0.000000\n",
      "     eval_roc_auc_micro  0.500000\n",
      "          eval_f1_macro  0.000000\n",
      "   eval_precision_macro  0.000000\n",
      "      eval_recall_macro  0.000000\n",
      "     eval_roc_auc_macro  0.500000\n",
      "        eval_f1_samples  0.000000\n",
      " eval_precision_samples  0.000000\n",
      "    eval_recall_samples  0.000000\n",
      "   eval_roc_auc_samples  0.500000\n",
      "       eval_f1_weighted  0.000000\n",
      "eval_precision_weighted  0.000000\n",
      "   eval_recall_weighted  0.000000\n",
      "  eval_roc_auc_weighted  0.500000\n",
      "           eval_runtime  3.306200\n",
      "eval_samples_per_second 30.246000\n",
      "  eval_steps_per_second 10.284000\n",
      "                  epoch  1.000000\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push to Hugging Face"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T20:21:51.722736Z",
     "start_time": "2024-07-16T20:21:07.011908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.push_to_hub(repo_id=hub_model_id, token=HfFolder.get_token())\n",
    "tokenizer.push_to_hub(repo_id=hub_model_id, token=HfFolder.get_token())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Update Hugging Face Model Card"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T21:24:43.821473Z",
     "start_time": "2024-07-16T21:24:42.128911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from huggingface_hub import ModelCard, EvalResult, ModelCardData\n",
    "import platform\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "training_regime = []\n",
    "training_regime_args = args.to_sanitized_dict()\n",
    "for k,v in training_regime_args.items():\n",
    "    if (isinstance(v, (int, str, bool, float))\n",
    "            and '_dir' not in k\n",
    "            and 'logging' not in k\n",
    "            and 'log_' not in k\n",
    "            and 'hub_' not in k\n",
    "            and '_hub' not in k\n",
    "            and 'save_' not in k\n",
    "            and 'run_name' not in k\n",
    "            and 'debug' not in k\n",
    "            and 'token' not in k):\n",
    "        training_regime.append(f'{k}={json.dumps(v)}')\n",
    "\n",
    "training_regime = sorted(training_regime)\n",
    "\n",
    "training_regime = ', '.join(training_regime)\n",
    "\n",
    "\n",
    "## Hardware\n",
    "compute_infrastructure = []\n",
    "mem_total = !cat /proc/meminfo | grep MemTotal\n",
    "mem_total = list(set(mem_total))[0]\n",
    "cpu_info = !cat /proc/cpuinfo | grep \"model name\"\n",
    "cpu_count = len(list(cpu_info))\n",
    "cpu_name = list(set(cpu_info))[0]\n",
    "cpu_name = cpu_name.strip()\n",
    "cpu_name = cpu_name.replace('model name\\t:', '')\n",
    "cpu_name = cpu_name.strip()\n",
    "\n",
    "compute_infrastructure.append(f'- {platform.system()} {platform.release()} {platform.processor()}')\n",
    "compute_infrastructure.append(f'- {mem_total}')\n",
    "compute_infrastructure.append(f'- {cpu_count} X {cpu_name}')\n",
    "\n",
    "\n",
    "gpu_name = !nvidia-smi --query-gpu=gpu_name --format=csv,noheader\n",
    "gpus = set()\n",
    "for idx, gpu in enumerate(gpu_name):\n",
    "    compute_infrastructure.append(f\"- GPU_{idx}: {gpu}\")\n",
    "    gpus.add(gpu)\n",
    "\n",
    "gpus =list(gpus)\n",
    "compute_infrastructure = '\\n'.join(compute_infrastructure)\n",
    "hardware_type = f'{len(gpus)} X {gpus[0]}'\n",
    "\n",
    "## Software\n",
    "software_list = !pip list\n",
    "inc_software = []\n",
    "inc_software.append(f'python {platform.python_version()}')\n",
    "\n",
    "for software in software_list:\n",
    "    if software and '[notice]' not in software and '---' not in software and 'Package' not in software:\n",
    "        inc_software.append(' '.join(software.split()))\n",
    " \n",
    "\n",
    "software = \", \".join(inc_software)   \n",
    "\n",
    "hours_used = \"\"\n",
    "eval_results = []\n",
    "for k, v in test_results.items():\n",
    "    metric_type = k.replace(\"eval_\", \"\", 1)\n",
    "    if metric_type == 'runtime':\n",
    "        hours_used = f\"{int(v)/60.0:.2f}\"\n",
    "    eval_results.append(EvalResult(\n",
    "        task_type='multi_label_classification',\n",
    "        dataset_type='mix_human-eval_synthetic',\n",
    "        dataset_name=dataset_id,\n",
    "        metric_type=metric_type,\n",
    "        metric_value=v))\n",
    "\n",
    "direct_use = \"\"\"\n",
    "    ```python\n",
    "    from transformers import pipeline\n",
    "\n",
    "    pipe = pipeline(\"text-classification\", model=\"${hub_model_id}\", return_all_scores=True)\n",
    "\n",
    "    results = pipe(\"Join our dynamic and fast-paced team as a Junior Marketing Specialist. We seek a tech-savvy and energetic individual who thrives in a vibrant environment. Ideal candidates are digital natives with a fresh perspective, ready to adapt quickly to new trends. You should have recent experience in social media strategies and a strong understanding of current digital marketing tools. We're looking for someone with a youthful mindset, eager to bring innovative ideas to our young and ambitious team. If you're a recent graduate or early in your career, this opportunity is perfect for you!\")\n",
    "    print(results)\n",
    "    ```\n",
    "    >> [[\n",
    "    {'label': 'age', 'score': 0.9883460402488708}, \n",
    "    {'label': 'disability', 'score': 0.00787709467113018}, \n",
    "    {'label': 'feminine', 'score': 0.007224376779049635}, \n",
    "    {'label': 'general', 'score': 0.09967829287052155}, \n",
    "    {'label': 'masculine', 'score': 0.0035264550242573023}, \n",
    "    {'label': 'racial', 'score': 0.014618005603551865}, \n",
    "    {'label': 'sexuality', 'score': 0.005568435415625572}\n",
    "    ]]\n",
    "    \"\"\"\n",
    "\n",
    "direct_use = direct_use.replace('${hub_model_id}', hub_model_id, -1)\n",
    "\n",
    "card_data = ModelCardData(\n",
    "    model_id=model_id,\n",
    "    model_name=model_id,\n",
    "    model_description=\"The model is a multi-label classifier designed to detect various types of bias within job descriptions.\",\n",
    "    base_model=base_model_id,\n",
    "    language='en',\n",
    "    license='apache-2.0',\n",
    "    developers=\"Tristan Everitt and Paul Ryan\",\n",
    "    model_card_authors='See developers',\n",
    "    model_card_contact='See developers',\n",
    "    repo=\"https://gitlab.computing.dcu.ie/everitt2/2024-mcm-everitt-ryan\",\n",
    "    training_regime=training_regime,\n",
    "    eval_results=eval_results,\n",
    "    results=markdown_classification_report,\n",
    "    compute_infrastructure=compute_infrastructure,\n",
    "    # hardware_requirements='N/A',\n",
    "    software=software,\n",
    "    hardware_type=hardware_type,\n",
    "    hours_used=hours_used,\n",
    "    cloud_provider='N/A',\n",
    "    cloud_region='N/A',\n",
    "    co2_emitted='N/A',\n",
    "    datasets=[dataset_id],\n",
    "    direct_use=direct_use\n",
    ")\n",
    "\n",
    "card = ModelCard.from_template(card_data)\n",
    "\n",
    "card.push_to_hub(repo_id=hub_model_id, token=HfFolder.get_token())"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/2024-mcm-everitt-ryan/bert-base-uncased-job-bias-seq-cls-dummy/commit/cdb63e126aa0112fa7365a3d09be408a3b3c2d4e', commit_message='Upload README.md with huggingface_hub', commit_description='', oid='cdb63e126aa0112fa7365a3d09be408a3b3c2d4e', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMiblo1Ci0GTlAbbA5wB3mn",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Fine-tuning BERT (and friends) for multi-label text classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "091f8220f33241f288faa0612853585f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6111a73e684a47769bda7183a836ee91",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8b1899a0c4b144d7a5e6599f8afb8b65",
      "value": 3
     }
    },
    "1045bb16e3694410898a73cf1b848917": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbba60f793c14100934a268063f63d26",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cd3570ddf67541d7818d97e236c54e54",
      "value": " 3/3 [00:00&lt;00:00, 75.93it/s]"
     }
    },
    "308fa6a7348140ec981a8d6c7d31f346": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5080d322a8034924b652b379c04667ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6111a73e684a47769bda7183a836ee91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b1899a0c4b144d7a5e6599f8afb8b65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8bc92587e35443488445e7521fbd0a13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5080d322a8034924b652b379c04667ed",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cb95e545fbdd4e99903bf634df694c9f",
      "value": "100%"
     }
    },
    "9a1aa9f2cc29473f9f8e5459d2641e76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8bc92587e35443488445e7521fbd0a13",
       "IPY_MODEL_091f8220f33241f288faa0612853585f",
       "IPY_MODEL_1045bb16e3694410898a73cf1b848917"
      ],
      "layout": "IPY_MODEL_308fa6a7348140ec981a8d6c7d31f346"
     }
    },
    "bbba60f793c14100934a268063f63d26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb95e545fbdd4e99903bf634df694c9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd3570ddf67541d7818d97e236c54e54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
