{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T17:25:58.631351Z",
     "start_time": "2024-07-01T17:25:58.625668Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Base Model\n",
    "\n",
    "base_model_id = 'bert-base-uncased'\n",
    "\n",
    "\n",
    "seed = 2024\n",
    "\n",
    "# Training\n",
    "num_train_epochs=10\n",
    "batch_size = 32\n",
    "learning_rate = 5e-5\n",
    "\n",
    "# Regularisation\n",
    "hidden_dropout_prob=0.02\n",
    "attention_probs_dropout_prob=0.00\n",
    "weight_decay=0.001\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "label_threshold=0.5\n",
    "\n",
    "use_gradient_checkpointing = False #True,  # Save some memory at the expense of training\n",
    "# See https://huggingface.co/docs/transformers/main/en/perf_train_gpu_one\n",
    "\n",
    "hf_site_id = '2024-mcm-everitt-ryan'\n",
    "dataset_id = f'{hf_site_id}/job-bias-synthetic-human-verified'\n",
    "\n",
    "#dataset_id = f'{hf_site_id}/job-bias-synthetic-human-verified'\n",
    "\n",
    "\n",
    "base_model_name = base_model_id.split('/')[-1]\n",
    "model_id = f'{base_model_name}-job-bias-verified'\n",
    "hub_model_id = f'{hf_site_id}/{model_id}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T10:21:12.596958Z",
     "start_time": "2024-05-24T10:21:10.188604Z"
    },
    "id": "4wxY3x-ZZz8h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.1.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython -m pip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets sentencepiece accelerate evaluate hf_transfer huggingface_hub scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T17:26:10.595794Z",
     "start_time": "2024-07-01T17:26:01.240714Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "9a1aa9f2cc29473f9f8e5459d2641e76",
      "308fa6a7348140ec981a8d6c7d31f346",
      "8bc92587e35443488445e7521fbd0a13",
      "091f8220f33241f288faa0612853585f",
      "1045bb16e3694410898a73cf1b848917",
      "cb95e545fbdd4e99903bf634df694c9f",
      "5080d322a8034924b652b379c04667ed",
      "8b1899a0c4b144d7a5e6599f8afb8b65",
      "6111a73e684a47769bda7183a836ee91",
      "cd3570ddf67541d7818d97e236c54e54",
      "bbba60f793c14100934a268063f63d26"
     ]
    },
    "id": "sd1LiXGjZ420",
    "outputId": "1b5783cd-0e4e-4c92-c67c-57b9288f2381"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e24b1fe1174462bbba3969a0a371444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8262f06fe3244fcbb462b6f6bba34169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584bccf55330401c8eb229c810a859e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/988k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0154b4d512684332b381b79e637d30d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.00M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c456eaada9944a9eb0af22ece0449f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c682a4dc85a54113b9c808174de8ddc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split:   0%|          | 0/314 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2847b138be484ed0bc4b603e39142a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1046 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'label_age', 'label_disability', 'label_masculine', 'label_feminine', 'label_racial', 'label_sexuality', 'label_general', 'text'],\n",
       "        num_rows: 1256\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['id', 'label_age', 'label_disability', 'label_masculine', 'label_feminine', 'label_racial', 'label_sexuality', 'label_general', 'text'],\n",
       "        num_rows: 314\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'label_age', 'label_disability', 'label_masculine', 'label_feminine', 'label_racial', 'label_sexuality', 'label_general', 'text'],\n",
       "        num_rows: 1046\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(dataset_id)\n",
    "column_names = dataset['train'].column_names\n",
    "\n",
    "\n",
    "text_col = 'text'\n",
    "label_cols = [col for col in column_names if col.startswith('label_')]\n",
    "\n",
    "labels = [label.replace(\"label_\", \"\") for label in label_cols]\n",
    "\n",
    "id2label = {idx: label for idx, label in enumerate(labels)}\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "# Remove all columns apart from the two needed for multi-class classification\n",
    "keep_columns = ['id', text_col] + label_cols\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    dataset[split] = dataset[split].remove_columns(\n",
    "        [col for col in dataset[split].column_names if col not in keep_columns])\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T17:28:51.475180Z",
     "start_time": "2024-07-01T17:28:51.439449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label_age</th>\n",
       "      <th>label_disability</th>\n",
       "      <th>label_masculine</th>\n",
       "      <th>label_feminine</th>\n",
       "      <th>label_racial</th>\n",
       "      <th>label_sexuality</th>\n",
       "      <th>label_general</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Synthetic:meta-llama:Meta-Llama-3-70B-Instruct...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Company: Lewis-Estrada\\nJob Title: Cashier\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kaggle::techmap::61377d32f2fd7421561f6664::see...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Have you worked at 2Degrees, Slingshot, Skinny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kaggle::techmap::61427019a973d70733cfaec4::bri...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>About the role\\n\\nAre you looking to join our ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label_age  \\\n",
       "0  Synthetic:meta-llama:Meta-Llama-3-70B-Instruct...      False   \n",
       "1  Kaggle::techmap::61377d32f2fd7421561f6664::see...       True   \n",
       "2  Kaggle::techmap::61427019a973d70733cfaec4::bri...       True   \n",
       "\n",
       "   label_disability  label_masculine  label_feminine  label_racial  \\\n",
       "0             False            False           False         False   \n",
       "1             False            False           False         False   \n",
       "2             False            False            True         False   \n",
       "\n",
       "   label_sexuality  label_general  \\\n",
       "0            False          False   \n",
       "1            False          False   \n",
       "2            False           True   \n",
       "\n",
       "                                                text  \n",
       "0  Company: Lewis-Estrada\\nJob Title: Cashier\\n\\n...  \n",
       "1  Have you worked at 2Degrees, Slingshot, Skinny...  \n",
       "2  About the role\\n\\nAre you looking to join our ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Merge train,val, test into one dataframe\n",
    "df = pd.concat([\n",
    "    dataset['train'].to_pandas(),\n",
    "    dataset['val'].to_pandas(),\n",
    "    dataset['test'].to_pandas()])\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T17:29:03.777886Z",
     "start_time": "2024-07-01T17:29:03.770686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Consumer, Business and Digital Banking – We work with our retail banking, business banking, consumer lending, mortgage, and digital banking businesses to define far-reaching technology strategies to evolve our customer experiences, to make us easier to do business with, and to deliver solutions that provide real value. This includes all core consumer deposit, loan, and payment processing and servicing platforms, all core channel systems for retail branches, ATMs, and call centers, custom-built online and mobile banking platforms, and mtb.com and marketing ecosystem capabilities.\\n\\nOverview:\\n- Manages the activities of several Technology Team Leaders or units and is responsible for each Team’s/unit’s development and systems support efforts.\\n- Provides day-to-day direction for the units and applications in line with the goals of the department and the clients they support.\\n- Responsible for managing client relations and expectations.\\n- Manages the project queue for their area.\\n- Strives to achieve individual and organizational objectives at minimum cost.\\n\\nPrimary Responsibilities:\\n- Manage and participate in consults with client management in the analysis of short-range business requirements and recommend innovations that anticipate the future impact of changing business requirements.\\n- Responsible for building a positive client relationship.\\n- Monitor the technology direction of the industry and vendor applications.\\n- Oversee application development, support testing efforts, technology infrastructure/project management, and other technology domains.\\n- Build rapport within the organization.\\n- Communicate and develop a professional level of communication and cooperation.\\n- Control the activities of the teams, assign personnel to various projects, and direct their activities.\\n- Ensure completion of schedules.\\n- Responsible for short-term staffing planning.\\n- Ensure adherence to all Department and Technology standards and procedures, including all documentation requirements.\\n- May translate requirements to assist staff in preparing detailed specifications for system enhancements.\\n- Manage recommended designs based on business and technology requirements.\\n- Identify issues and concerns.\\n- Manage monitoring project plans.\\n- May coordinate major project activities.\\n- Remain current on activities outside the team that may impact the team or client environment.\\n- Develop and manage multiple cost center budgets.\\n\\nEducation and Experience Required:\\n- Minimum of an Associate’s degree and 7 years’ technology or systems management/leadership experience, or in lieu of a degree a combined minimum of 9 years’ higher education and/or work experience, including a minimum of 7 years’ technology or systems management/leadership experience.\\n- Capable of working on multiple projects of a complex nature.\\n- Proficiency with project management, word processing, and spreadsheet applications.\\n- Complete understanding of the system development life cycle.\\n- Excellent problem-solving skills to assist in issue resolution.\\n- Familiar with application development software and hardware platforms.\\n- Excellent verbal and written communication skills.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Longest phrase\n",
    "longest_text = df[text_col].apply(lambda x: (len(x), x)).max()[1]\n",
    "longest_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T17:30:00.135205Z",
     "start_time": "2024-07-01T17:29:59.993343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_prefix_space=True)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T17:30:06.795705Z",
     "start_time": "2024-07-01T17:30:06.789790Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max characters: 3170\n",
      "Max words: 442\n",
      "Max tokens: 548\n"
     ]
    }
   ],
   "source": [
    "max_char = len(longest_text)\n",
    "max_words = len(longest_text.split())\n",
    "max_tokens = len(tokenizer.encode(longest_text))\n",
    "\n",
    "print(f'Max characters: {max_char}')\n",
    "print(f'Max words: {max_words}')\n",
    "print(f'Max tokens: {max_tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T17:30:15.745305Z",
     "start_time": "2024-07-01T17:30:15.742461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_max_length = min(max_tokens, tokenizer.model_max_length)\n",
    "tokenizer_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T17:30:18.135860Z",
     "start_time": "2024-07-01T17:30:18.132132Z"
    },
    "id": "AFWlSsbZaRLc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def preprocess_data(sample):\n",
    "    # take a batch of texts\n",
    "    text = sample[text_col]\n",
    "    # encode them\n",
    "    encoding = tokenizer(text, truncation=True, max_length=tokenizer_max_length, padding=\"max_length\")\n",
    "    #encoding = tokenizer(text, truncation=True, max_length=tokenizer_max_length, padding=True)\n",
    "    # add labels\n",
    "    labels_batch = {k: sample[k] for k in sample.keys() if k in label_cols}\n",
    "    # create numpy array of shape (batch_size, num_labels)\n",
    "    labels_matrix = np.zeros((len(text), len(label_cols)))\n",
    "    # fill numpy array\n",
    "    for idx, label in enumerate(label_cols):\n",
    "        labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "    encoding[\"labels\"] = labels_matrix.tolist()\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T17:30:24.593885Z",
     "start_time": "2024-07-01T17:30:22.070052Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4ENBTdulBEI",
    "outputId": "02554a1f-4961-461a-bf29-555b8debeabf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be4c7f5550e454faddaaacb2d27f103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce8b1ee0af74f49920dfe13df3605e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/314 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd48e972fff4706b2e8c9fb12026f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1046 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ds_train = ds_train.map(tokenize, batched=True, batch_size=len(ds_train))\n",
    "encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)\n",
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5qSmCgWefWs"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T10:21:17.136876Z",
     "start_time": "2024-05-24T10:21:15.632343Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XPL1Z_RegBF",
    "outputId": "22994300-8c93-421e-faa4-678d6cc14aab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.02, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.02, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.02, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.02, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(base_model_id,\n",
    "                                                           problem_type=\"multi_label_classification\",\n",
    "                                                           num_labels=len(label_cols),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id,\n",
    "                                                           hidden_dropout_prob=hidden_dropout_prob,\n",
    "                                                          # attention_probs_dropout_prob=attention_probs_dropout_prob\n",
    "                                                          )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T10:21:17.142273Z",
     "start_time": "2024-05-24T10:21:17.138307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.02,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"age\",\n",
       "    \"1\": \"disability\",\n",
       "    \"2\": \"masculine\",\n",
       "    \"3\": \"feminine\",\n",
       "    \"4\": \"racial\",\n",
       "    \"5\": \"sexuality\",\n",
       "    \"6\": \"general\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"age\": 0,\n",
       "    \"disability\": 1,\n",
       "    \"feminine\": 3,\n",
       "    \"general\": 6,\n",
       "    \"masculine\": 2,\n",
       "    \"racial\": 4,\n",
       "    \"sexuality\": 5\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"problem_type\": \"multi_label_classification\",\n",
       "  \"transformers_version\": \"4.42.3\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T10:21:18.065316Z",
     "start_time": "2024-05-24T10:21:17.752526Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, accuracy_score, classification_report\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "\n",
    "\n",
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "# added extras\n",
    "def multi_label_metrics(predictions, labels):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= label_threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    \n",
    "    f1_micro = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    f1_macro = f1_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "    f1_samples = f1_score(y_true=y_true, y_pred=y_pred, average='samples')\n",
    "    f1_weighted = f1_score(y_true=y_true, y_pred=y_pred, average='weighted')\n",
    "\n",
    "    precision_micro = precision_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    recall_micro = recall_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc_micro = roc_auc_score(y_true=y_true, y_score=y_pred, average='micro')\n",
    "\n",
    "    print(classification_report(y_true, y_pred, target_names=list(id2label.values())))\n",
    "    \n",
    "    # return as dictionary\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        f'f1_micro': f1_micro,\n",
    "        f'f1_macro': f1_macro,\n",
    "        f'f1_samples': f1_samples,\n",
    "        f'f1_weighted': f1_weighted,\n",
    "        f'precision_micro': precision_micro,\n",
    "        f'recall_micro': recall_micro,\n",
    "        f'roc_auc_micro': roc_auc_micro}\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds,\n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-X2brZcv0X6"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T10:49:47.418670Z",
     "start_time": "2024-05-24T10:21:18.066341Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KXmFds8js6P8",
    "outputId": "66ebb2ab-f93f-48aa-a4dc-36f55f2f8559"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 02:40, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Samples</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>Precision Micro</th>\n",
       "      <th>Recall Micro</th>\n",
       "      <th>Roc Auc Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.266314</td>\n",
       "      <td>0.515924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.229900</td>\n",
       "      <td>0.248140</td>\n",
       "      <td>0.515924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.192700</td>\n",
       "      <td>0.193946</td>\n",
       "      <td>0.611465</td>\n",
       "      <td>0.331707</td>\n",
       "      <td>0.311432</td>\n",
       "      <td>0.107219</td>\n",
       "      <td>0.254987</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.600812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.165815</td>\n",
       "      <td>0.675159</td>\n",
       "      <td>0.548872</td>\n",
       "      <td>0.521751</td>\n",
       "      <td>0.222611</td>\n",
       "      <td>0.495535</td>\n",
       "      <td>0.737374</td>\n",
       "      <td>0.437126</td>\n",
       "      <td>0.712162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.094800</td>\n",
       "      <td>0.153179</td>\n",
       "      <td>0.707006</td>\n",
       "      <td>0.617450</td>\n",
       "      <td>0.603855</td>\n",
       "      <td>0.280998</td>\n",
       "      <td>0.575170</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.550898</td>\n",
       "      <td>0.765848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.142202</td>\n",
       "      <td>0.738854</td>\n",
       "      <td>0.647273</td>\n",
       "      <td>0.629970</td>\n",
       "      <td>0.275159</td>\n",
       "      <td>0.602500</td>\n",
       "      <td>0.824074</td>\n",
       "      <td>0.532934</td>\n",
       "      <td>0.761790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.138892</td>\n",
       "      <td>0.751592</td>\n",
       "      <td>0.675958</td>\n",
       "      <td>0.676120</td>\n",
       "      <td>0.299575</td>\n",
       "      <td>0.656854</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.580838</td>\n",
       "      <td>0.784757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.040800</td>\n",
       "      <td>0.138000</td>\n",
       "      <td>0.748408</td>\n",
       "      <td>0.668990</td>\n",
       "      <td>0.665751</td>\n",
       "      <td>0.297452</td>\n",
       "      <td>0.645501</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.574850</td>\n",
       "      <td>0.781517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.142623</td>\n",
       "      <td>0.742038</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.650402</td>\n",
       "      <td>0.284713</td>\n",
       "      <td>0.628022</td>\n",
       "      <td>0.814159</td>\n",
       "      <td>0.550898</td>\n",
       "      <td>0.770279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.141701</td>\n",
       "      <td>0.742038</td>\n",
       "      <td>0.657244</td>\n",
       "      <td>0.652032</td>\n",
       "      <td>0.287898</td>\n",
       "      <td>0.629941</td>\n",
       "      <td>0.801724</td>\n",
       "      <td>0.556886</td>\n",
       "      <td>0.772781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         age       0.00      0.00      0.00        25\n",
      "  disability       0.00      0.00      0.00        26\n",
      "   masculine       0.00      0.00      0.00        27\n",
      "    feminine       0.00      0.00      0.00        20\n",
      "      racial       0.00      0.00      0.00        15\n",
      "   sexuality       0.00      0.00      0.00        27\n",
      "     general       0.00      0.00      0.00        27\n",
      "\n",
      "   micro avg       0.00      0.00      0.00       167\n",
      "   macro avg       0.00      0.00      0.00       167\n",
      "weighted avg       0.00      0.00      0.00       167\n",
      " samples avg       0.00      0.00      0.00       167\n",
      "\n",
      "----------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         age       0.00      0.00      0.00        25\n",
      "  disability       0.00      0.00      0.00        26\n",
      "   masculine       0.00      0.00      0.00        27\n",
      "    feminine       0.00      0.00      0.00        20\n",
      "      racial       0.00      0.00      0.00        15\n",
      "   sexuality       0.00      0.00      0.00        27\n",
      "     general       0.00      0.00      0.00        27\n",
      "\n",
      "   micro avg       0.00      0.00      0.00       167\n",
      "   macro avg       0.00      0.00      0.00       167\n",
      "weighted avg       0.00      0.00      0.00       167\n",
      " samples avg       0.00      0.00      0.00       167\n",
      "\n",
      "----------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         age       0.57      0.16      0.25        25\n",
      "  disability       0.00      0.00      0.00        26\n",
      "   masculine       0.00      0.00      0.00        27\n",
      "    feminine       1.00      0.75      0.86        20\n",
      "      racial       0.92      0.73      0.81        15\n",
      "   sexuality       1.00      0.15      0.26        27\n",
      "     general       0.00      0.00      0.00        27\n",
      "\n",
      "   micro avg       0.89      0.20      0.33       167\n",
      "   macro avg       0.50      0.26      0.31       167\n",
      "weighted avg       0.45      0.20      0.25       167\n",
      " samples avg       0.11      0.11      0.11       167\n",
      "\n",
      "----------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         age       0.64      0.28      0.39        25\n",
      "  disability       0.58      0.42      0.49        26\n",
      "   masculine       0.53      0.30      0.38        27\n",
      "    feminine       0.85      0.85      0.85        20\n",
      "      racial       0.90      0.60      0.72        15\n",
      "   sexuality       0.88      0.78      0.82        27\n",
      "     general       0.00      0.00      0.00        27\n",
      "\n",
      "   micro avg       0.74      0.44      0.55       167\n",
      "   macro avg       0.62      0.46      0.52       167\n",
      "weighted avg       0.60      0.44      0.50       167\n",
      " samples avg       0.23      0.22      0.22       167\n",
      "\n",
      "----------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         age       0.78      0.56      0.65        25\n",
      "  disability       0.57      0.62      0.59        26\n",
      "   masculine       0.47      0.56      0.51        27\n",
      "    feminine       0.89      0.80      0.84        20\n",
      "      racial       0.92      0.80      0.86        15\n",
      "   sexuality       0.86      0.70      0.78        27\n",
      "     general       0.00      0.00      0.00        27\n",
      "\n",
      "   micro avg       0.70      0.55      0.62       167\n",
      "   macro avg       0.64      0.58      0.60       167\n",
      "weighted avg       0.61      0.55      0.58       167\n",
      " samples avg       0.29      0.28      0.28       167\n",
      "\n",
      "----------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         age       0.69      0.36      0.47        25\n",
      "  disability       0.71      0.58      0.64        26\n",
      "   masculine       0.75      0.33      0.46        27\n",
      "    feminine       0.89      0.85      0.87        20\n",
      "      racial       0.93      0.87      0.90        15\n",
      "   sexuality       0.88      0.85      0.87        27\n",
      "     general       1.00      0.11      0.20        27\n",
      "\n",
      "   micro avg       0.82      0.53      0.65       167\n",
      "   macro avg       0.84      0.56      0.63       167\n",
      "weighted avg       0.83      0.53      0.60       167\n",
      " samples avg       0.28      0.27      0.28       167\n",
      "\n",
      "----------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         age       0.64      0.36      0.46        25\n",
      "  disability       0.64      0.54      0.58        26\n",
      "   masculine       0.79      0.41      0.54        27\n",
      "    feminine       0.90      0.90      0.90        20\n",
      "      racial       0.92      0.80      0.86        15\n",
      "   sexuality       0.88      0.85      0.87        27\n",
      "     general       0.91      0.37      0.53        27\n",
      "\n",
      "   micro avg       0.81      0.58      0.68       167\n",
      "   macro avg       0.81      0.60      0.68       167\n",
      "weighted avg       0.80      0.58      0.66       167\n",
      " samples avg       0.31      0.30      0.30       167\n",
      "\n",
      "----------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         age       0.67      0.40      0.50        25\n",
      "  disability       0.67      0.62      0.64        26\n",
      "   masculine       0.69      0.41      0.51        27\n",
      "    feminine       0.89      0.85      0.87        20\n",
      "      racial       0.92      0.80      0.86        15\n",
      "   sexuality       0.88      0.85      0.87        27\n",
      "     general       1.00      0.26      0.41        27\n",
      "\n",
      "   micro avg       0.80      0.57      0.67       167\n",
      "   macro avg       0.82      0.60      0.67       167\n",
      "weighted avg       0.81      0.57      0.65       167\n",
      " samples avg       0.31      0.29      0.30       167\n",
      "\n",
      "----------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         age       0.67      0.32      0.43        25\n",
      "  disability       0.67      0.54      0.60        26\n",
      "   masculine       0.71      0.37      0.49        27\n",
      "    feminine       0.90      0.90      0.90        20\n",
      "      racial       0.92      0.80      0.86        15\n",
      "   sexuality       0.88      0.85      0.87        27\n",
      "     general       1.00      0.26      0.41        27\n",
      "\n",
      "   micro avg       0.81      0.55      0.66       167\n",
      "   macro avg       0.82      0.58      0.65       167\n",
      "weighted avg       0.81      0.55      0.63       167\n",
      " samples avg       0.29      0.28      0.28       167\n",
      "\n",
      "----------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         age       0.67      0.32      0.43        25\n",
      "  disability       0.64      0.54      0.58        26\n",
      "   masculine       0.69      0.41      0.51        27\n",
      "    feminine       0.90      0.90      0.90        20\n",
      "      racial       0.92      0.80      0.86        15\n",
      "   sexuality       0.88      0.85      0.87        27\n",
      "     general       1.00      0.26      0.41        27\n",
      "\n",
      "   micro avg       0.80      0.56      0.66       167\n",
      "   macro avg       0.81      0.58      0.65       167\n",
      "weighted avg       0.81      0.56      0.63       167\n",
      " samples avg       0.30      0.28      0.29       167\n",
      "\n",
      "----------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=400, training_loss=0.12981932155787945, metrics={'train_runtime': 161.3821, 'train_samples_per_second': 77.828, 'train_steps_per_second': 2.479, 'total_flos': 3304823212032000.0, 'train_loss': 0.12981932155787945, 'epoch': 10.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding,TrainerCallback\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "metric_name = 'loss' #\"f1_micro\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    model_id,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=learning_rate,\n",
    "    #optim=optimiser,\n",
    "    #lr_scheduler_type=\"cosine\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    weight_decay=weight_decay,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    fp16=False,\n",
    "    gradient_checkpointing=use_gradient_checkpointing,\n",
    "    overwrite_output_dir=True,\n",
    "    #push_to_hub=True,\n",
    "    #output_dir=repository_id,\n",
    "    #logging_dir=f\"{model_id}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    #warmup_steps=500,\n",
    "    #warmup_ratio=0.1,\n",
    "    #max_grad_norm=0.3,\n",
    "    save_total_limit=3,\n",
    "    #report_to=\"tensorboard\",\n",
    "    #push_to_hub=True,\n",
    "    #hub_strategy=\"every_save\",\n",
    "    #hub_model_id=hub_model_id,\n",
    "    #hub_token=HfFolder.get_token(),\n",
    ")\n",
    "\n",
    "#early_stop = transformers.EarlyStoppingCallback(10, 1.15)\n",
    "class PrintClassificationCallback(TrainerCallback):\n",
    "    def on_evaluate(self, args, state, control, logs=None, **kwargs):\n",
    "        print(\"----------------------------------------------------------\")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"val\"],\n",
    "    # For padding a batch of examples to the maximum length seen in the batch\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[PrintClassificationCallback]\n",
    "    #tokenizer=tokenizer,\n",
    "    #   callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # Silence the warnings.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         age       0.74      0.46      0.56        81\n",
      "  disability       0.75      0.62      0.68        81\n",
      "   masculine       0.88      0.38      0.53        79\n",
      "    feminine       0.86      0.92      0.89        76\n",
      "      racial       0.85      0.73      0.79        78\n",
      "   sexuality       0.80      0.88      0.84        81\n",
      "     general       1.00      0.30      0.47        82\n",
      "\n",
      "   micro avg       0.82      0.61      0.70       558\n",
      "   macro avg       0.84      0.61      0.68       558\n",
      "weighted avg       0.84      0.61      0.68       558\n",
      " samples avg       0.32      0.32      0.32       558\n",
      "\n",
      "----------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.13193343579769135,\n",
       " 'eval_accuracy': 0.7839388145315488,\n",
       " 'eval_f1_micro': 0.7003089598352215,\n",
       " 'eval_f1_macro': 0.6788635860334568,\n",
       " 'eval_f1_samples': 0.32023581899298914,\n",
       " 'eval_f1_weighted': 0.6765300657386585,\n",
       " 'eval_precision_micro': 0.8232445520581114,\n",
       " 'eval_recall_micro': 0.6093189964157706,\n",
       " 'eval_roc_auc_micro': 0.7992632829506411,\n",
       " 'eval_runtime': 3.5617,\n",
       " 'eval_samples_per_second': 293.684,\n",
       " 'eval_steps_per_second': 9.265,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = trainer.evaluate(eval_dataset=encoded_dataset['test'])\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T10:50:14.331642Z",
     "start_time": "2024-05-24T10:50:14.315272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric      Value\n",
      "              eval_loss   0.131933\n",
      "          eval_accuracy   0.783939\n",
      "          eval_f1_micro   0.700309\n",
      "          eval_f1_macro   0.678864\n",
      "        eval_f1_samples   0.320236\n",
      "       eval_f1_weighted   0.676530\n",
      "   eval_precision_micro   0.823245\n",
      "      eval_recall_micro   0.609319\n",
      "     eval_roc_auc_micro   0.799263\n",
      "           eval_runtime   3.561700\n",
      "eval_samples_per_second 293.684000\n",
      "  eval_steps_per_second   9.265000\n",
      "                  epoch  10.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(list(test_results.items()), columns=['Metric', 'Value'])\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107111aec043489c9b13c713db1189b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49c9555d6d742429b313ecad258eec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from huggingface_hub import ModelCard, EvalResult, ModelCardData\n",
    "import platform\n",
    "import sys\n",
    "import os\n",
    "\n",
    "model.push_to_hub(repo_id=hub_model_id, token=HfFolder.get_token())\n",
    "tokenizer.push_to_hub(repo_id=hub_model_id, token=HfFolder.get_token())\n",
    "\n",
    "###### Update Model Card ######\n",
    "\n",
    "eval_results = []\n",
    "for k, v in test_results.items():\n",
    "    eval_results.append(EvalResult(\n",
    "        task_type='multi_label_classification',\n",
    "        dataset_type='mix_human-eval_synthetic',\n",
    "        dataset_name=dataset_id,\n",
    "        metric_type=k.replace(\"eval_\", \"\", 1),\n",
    "        metric_value=v))\n",
    "\n",
    "direct_use = \"\"\"\n",
    "    ```python\n",
    "    from transformers import pipeline\n",
    "\n",
    "    pipe = pipeline(\"text-classification\", model=\"${hub_model_id}\", return_all_scores=True)\n",
    "\n",
    "    results = pipe(\"Join our dynamic and fast-paced team as a Junior Marketing Specialist. We seek a tech-savvy and energetic individual who thrives in a vibrant environment. Ideal candidates are digital natives with a fresh perspective, ready to adapt quickly to new trends. You should have recent experience in social media strategies and a strong understanding of current digital marketing tools. We're looking for someone with a youthful mindset, eager to bring innovative ideas to our young and ambitious team. If you're a recent graduate or early in your career, this opportunity is perfect for you!\")\n",
    "    print(results)\n",
    "    ```\n",
    "    >> [[\n",
    "    {'label': 'age', 'score': 0.9883460402488708}, \n",
    "    {'label': 'disability', 'score': 0.00787709467113018}, \n",
    "    {'label': 'feminine', 'score': 0.007224376779049635}, \n",
    "    {'label': 'general', 'score': 0.09967829287052155}, \n",
    "    {'label': 'masculine', 'score': 0.0035264550242573023}, \n",
    "    {'label': 'racial', 'score': 0.014618005603551865}, \n",
    "    {'label': 'sexuality', 'score': 0.005568435415625572}\n",
    "    ]]\n",
    "    \"\"\"\n",
    "direct_use = direct_use.replace('${hub_model_id}', hub_model_id, -1)\n",
    "\n",
    "card_data = ModelCardData(\n",
    "    model_id=model_id,\n",
    "    model_name=model_id,\n",
    "    model_description=\"The model is a multi-label classifier designed to detect various types of bias within job descriptions.\",\n",
    "    base_model=base_model_id,\n",
    "    language='en',\n",
    "    license='apache-2.0',\n",
    "    developers=\"Tristan Everitt and Paul Ryan\",\n",
    "    model_card_authors='See developers',\n",
    "    model_card_contact='See developers',\n",
    "    repo=\"https://gitlab.computing.dcu.ie/everitt2/2024-mcm-everitt-ryan\",\n",
    "    eval_results=eval_results,\n",
    "    compute_infrastructure=f'{platform.system()} {platform.release()} {platform.processor()}',\n",
    "    # hardware_requirements=f\"CPUs: {psutil.cpu_count()}, Memory: {psutil.virtual_memory().total} bytes\",\n",
    "    software=f'Python {platform.python_version()}',\n",
    "    hardware_type=platform.machine(),\n",
    "    hours_used='N/A',\n",
    "    cloud_provider='N/A',\n",
    "    cloud_region='N/A',\n",
    "    co2_emitted='N/A',\n",
    "    datasets=[dataset_id],\n",
    "    direct_use=direct_use\n",
    ")\n",
    "\n",
    "card = ModelCard.from_template(card_data)\n",
    "\n",
    "card.push_to_hub(repo_id=hub_model_id, token=HfFolder.get_token())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMiblo1Ci0GTlAbbA5wB3mn",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Fine-tuning BERT (and friends) for multi-label text classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "091f8220f33241f288faa0612853585f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6111a73e684a47769bda7183a836ee91",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8b1899a0c4b144d7a5e6599f8afb8b65",
      "value": 3
     }
    },
    "1045bb16e3694410898a73cf1b848917": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbba60f793c14100934a268063f63d26",
      "placeholder": "​",
      "style": "IPY_MODEL_cd3570ddf67541d7818d97e236c54e54",
      "value": " 3/3 [00:00&lt;00:00, 75.93it/s]"
     }
    },
    "308fa6a7348140ec981a8d6c7d31f346": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5080d322a8034924b652b379c04667ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6111a73e684a47769bda7183a836ee91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b1899a0c4b144d7a5e6599f8afb8b65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8bc92587e35443488445e7521fbd0a13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5080d322a8034924b652b379c04667ed",
      "placeholder": "​",
      "style": "IPY_MODEL_cb95e545fbdd4e99903bf634df694c9f",
      "value": "100%"
     }
    },
    "9a1aa9f2cc29473f9f8e5459d2641e76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8bc92587e35443488445e7521fbd0a13",
       "IPY_MODEL_091f8220f33241f288faa0612853585f",
       "IPY_MODEL_1045bb16e3694410898a73cf1b848917"
      ],
      "layout": "IPY_MODEL_308fa6a7348140ec981a8d6c7d31f346"
     }
    },
    "bbba60f793c14100934a268063f63d26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb95e545fbdd4e99903bf634df694c9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd3570ddf67541d7818d97e236c54e54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
